{"componentChunkName":"component---src-templates-post-template-post-template-tsx","path":"/llm/understanding-temperature-and-top-p-sampling-in-large-language-models","result":{"data":{"markdownRemark":{"id":"5fd341ff-6c79-5e2b-9641-149b654457a8","html":"<h1 id=\"understanding-temperature-and-top-p-sampling-in-large-language-models-a-deep-dive\" style=\"position:relative;\"><a href=\"#understanding-temperature-and-top-p-sampling-in-large-language-models-a-deep-dive\" aria-label=\"understanding temperature and top p sampling in large language models a deep dive permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Understanding Temperature and Top-p Sampling in Large Language Models: A Deep Dive</h1>\n<p>When working with Large Language Models (LLMs), two parameters often confound even experienced practitioners: temperature and top-p sampling. These parameters fundamentally control how LLMs generate text, yet their implications aren’t always intuitive. In this post, we’ll demystify these concepts and explore how they shape LLM outputs in practice.</p>\n<h2 id=\"the-foundation-probability-distributions-in-llms\" style=\"position:relative;\"><a href=\"#the-foundation-probability-distributions-in-llms\" aria-label=\"the foundation probability distributions in llms permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>The Foundation: Probability Distributions in LLMs</h2>\n<p>Before diving into sampling methods, let’s understand what we’re sampling from. When an LLM processes a prompt, it generates a probability distribution over its entire vocabulary for the next token. For example, given the prompt “The capital of France is”, the model might assign:</p>\n<ul>\n<li>“Paris” → 0.85 probability</li>\n<li>“Lyon” → 0.05 probability</li>\n<li>“London” → 0.02 probability</li>\n<li>Other tokens → remaining probability</li>\n</ul>\n<p>Without any sampling parameters, the model would simply choose the token with the highest probability (greedy decoding). However, this often leads to repetitive and deterministic outputs. This is where temperature and top-p sampling come in.</p>\n<h2 id=\"temperature-controlling-randomness\" style=\"position:relative;\"><a href=\"#temperature-controlling-randomness\" aria-label=\"temperature controlling randomness permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Temperature: Controlling Randomness</h2>\n<p>Temperature is perhaps the most widely known sampling parameter, typically ranging from 0.0 to 2.0. It works by modifying the probability distribution before sampling occurs. The mathematical transformation is:</p>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\">new_probabilities <span class=\"token operator\">=</span> exp<span class=\"token punctuation\">(</span>log<span class=\"token punctuation\">(</span>original_probabilities<span class=\"token punctuation\">)</span> <span class=\"token operator\">/</span> temperature<span class=\"token punctuation\">)</span></code></pre></div>\n<p>Let’s break down what different temperature values do:</p>\n<h3 id=\"understanding-temperature-through-examples\" style=\"position:relative;\"><a href=\"#understanding-temperature-through-examples\" aria-label=\"understanding temperature through examples permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Understanding Temperature Through Examples</h3>\n<p>Let’s explore how different temperature values transform probability distributions through concrete examples. Consider an LLM generating the next word after “The weather today is”:</p>\n<p>Initial probability distribution:</p>\n<ul>\n<li>“sunny” → 0.50</li>\n<li>“cloudy” → 0.30</li>\n<li>“rainy” → 0.15</li>\n<li>“stormy” → 0.05</li>\n</ul>\n<p>Let’s see how different temperatures affect these probabilities:</p>\n<h3 id=\"temperature--0-the-ice-age\" style=\"position:relative;\"><a href=\"#temperature--0-the-ice-age\" aria-label=\"temperature  0 the ice age permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Temperature = 0 (The Ice Age)</h3>\n<p>At temperature 0, we get a deterministic output:</p>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token comment\"># T = 0 effectively turns probabilities into:</span>\n<span class=\"token string\">\"sunny\"</span> → <span class=\"token number\">1.0</span> <span class=\"token punctuation\">(</span><span class=\"token number\">100</span><span class=\"token operator\">%</span><span class=\"token punctuation\">)</span>\n<span class=\"token string\">\"cloudy\"</span> → <span class=\"token number\">0.0</span> <span class=\"token punctuation\">(</span><span class=\"token number\">0</span><span class=\"token operator\">%</span><span class=\"token punctuation\">)</span>\n<span class=\"token string\">\"rainy\"</span> → <span class=\"token number\">0.0</span> <span class=\"token punctuation\">(</span><span class=\"token number\">0</span><span class=\"token operator\">%</span><span class=\"token punctuation\">)</span>\n<span class=\"token string\">\"stormy\"</span> → <span class=\"token number\">0.0</span> <span class=\"token punctuation\">(</span><span class=\"token number\">0</span><span class=\"token operator\">%</span><span class=\"token punctuation\">)</span></code></pre></div>\n<p>The model will always choose “sunny” as it has the highest probability. This makes outputs completely deterministic and is ideal for:</p>\n<ul>\n<li>Solving mathematical problems</li>\n<li>Writing code</li>\n<li>Generating structured data</li>\n</ul>\n<h3 id=\"temperature--05-cool-and-controlled\" style=\"position:relative;\"><a href=\"#temperature--05-cool-and-controlled\" aria-label=\"temperature  05 cool and controlled permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Temperature = 0.5 (Cool and Controlled)</h3>\n<p>Let’s calculate the new probabilities using the formula: p_new = exp(log(p)/0.5)</p>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token string\">\"sunny\"</span> → exp<span class=\"token punctuation\">(</span>log<span class=\"token punctuation\">(</span><span class=\"token number\">0.50</span><span class=\"token punctuation\">)</span><span class=\"token operator\">/</span><span class=\"token number\">0.5</span><span class=\"token punctuation\">)</span> ≈ <span class=\"token number\">0.70</span> <span class=\"token punctuation\">(</span><span class=\"token number\">70</span><span class=\"token operator\">%</span><span class=\"token punctuation\">)</span>\n<span class=\"token string\">\"cloudy\"</span> → exp<span class=\"token punctuation\">(</span>log<span class=\"token punctuation\">(</span><span class=\"token number\">0.30</span><span class=\"token punctuation\">)</span><span class=\"token operator\">/</span><span class=\"token number\">0.5</span><span class=\"token punctuation\">)</span> ≈ <span class=\"token number\">0.22</span> <span class=\"token punctuation\">(</span><span class=\"token number\">22</span><span class=\"token operator\">%</span><span class=\"token punctuation\">)</span>\n<span class=\"token string\">\"rainy\"</span> → exp<span class=\"token punctuation\">(</span>log<span class=\"token punctuation\">(</span><span class=\"token number\">0.15</span><span class=\"token punctuation\">)</span><span class=\"token operator\">/</span><span class=\"token number\">0.5</span><span class=\"token punctuation\">)</span> ≈ <span class=\"token number\">0.07</span> <span class=\"token punctuation\">(</span><span class=\"token number\">7</span><span class=\"token operator\">%</span><span class=\"token punctuation\">)</span>\n<span class=\"token string\">\"stormy\"</span> → exp<span class=\"token punctuation\">(</span>log<span class=\"token punctuation\">(</span><span class=\"token number\">0.05</span><span class=\"token punctuation\">)</span><span class=\"token operator\">/</span><span class=\"token number\">0.5</span><span class=\"token punctuation\">)</span> ≈ <span class=\"token number\">0.01</span> <span class=\"token punctuation\">(</span><span class=\"token number\">1</span><span class=\"token operator\">%</span><span class=\"token punctuation\">)</span></code></pre></div>\n<p>Notice how this temperature sharpens the distribution, making high-probability tokens even more likely while still maintaining some randomness. This works well for:</p>\n<ul>\n<li>Technical writing</li>\n<li>Structured creative tasks</li>\n<li>Semi-formal conversation</li>\n</ul>\n<h3 id=\"temperature--10-room-temperature\" style=\"position:relative;\"><a href=\"#temperature--10-room-temperature\" aria-label=\"temperature  10 room temperature permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Temperature = 1.0 (Room Temperature)</h3>\n<p>At temperature 1.0, we maintain the original probabilities:</p>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token string\">\"sunny\"</span> → <span class=\"token number\">0.50</span> <span class=\"token punctuation\">(</span><span class=\"token number\">50</span><span class=\"token operator\">%</span><span class=\"token punctuation\">)</span>\n<span class=\"token string\">\"cloudy\"</span> → <span class=\"token number\">0.30</span> <span class=\"token punctuation\">(</span><span class=\"token number\">30</span><span class=\"token operator\">%</span><span class=\"token punctuation\">)</span>\n<span class=\"token string\">\"rainy\"</span> → <span class=\"token number\">0.15</span> <span class=\"token punctuation\">(</span><span class=\"token number\">15</span><span class=\"token operator\">%</span><span class=\"token punctuation\">)</span>\n<span class=\"token string\">\"stormy\"</span> → <span class=\"token number\">0.05</span> <span class=\"token punctuation\">(</span><span class=\"token number\">5</span><span class=\"token operator\">%</span><span class=\"token punctuation\">)</span></code></pre></div>\n<p>This preserves the model’s original probability assessments, providing a balanced mix of creativity and coherence. Ideal for:</p>\n<ul>\n<li>General conversation</li>\n<li>Creative writing with constraints</li>\n<li>Summarization tasks</li>\n</ul>\n<h3 id=\"temperature--20-the-heat-is-on\" style=\"position:relative;\"><a href=\"#temperature--20-the-heat-is-on\" aria-label=\"temperature  20 the heat is on permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Temperature = 2.0 (The Heat Is On)</h3>\n<p>Let’s calculate: p_new = exp(log(p)/2.0)</p>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token string\">\"sunny\"</span> → exp<span class=\"token punctuation\">(</span>log<span class=\"token punctuation\">(</span><span class=\"token number\">0.50</span><span class=\"token punctuation\">)</span><span class=\"token operator\">/</span><span class=\"token number\">2.0</span><span class=\"token punctuation\">)</span> ≈ <span class=\"token number\">0.35</span> <span class=\"token punctuation\">(</span><span class=\"token number\">35</span><span class=\"token operator\">%</span><span class=\"token punctuation\">)</span>\n<span class=\"token string\">\"cloudy\"</span> → exp<span class=\"token punctuation\">(</span>log<span class=\"token punctuation\">(</span><span class=\"token number\">0.30</span><span class=\"token punctuation\">)</span><span class=\"token operator\">/</span><span class=\"token number\">2.0</span><span class=\"token punctuation\">)</span> ≈ <span class=\"token number\">0.27</span> <span class=\"token punctuation\">(</span><span class=\"token number\">27</span><span class=\"token operator\">%</span><span class=\"token punctuation\">)</span>\n<span class=\"token string\">\"rainy\"</span> → exp<span class=\"token punctuation\">(</span>log<span class=\"token punctuation\">(</span><span class=\"token number\">0.15</span><span class=\"token punctuation\">)</span><span class=\"token operator\">/</span><span class=\"token number\">2.0</span><span class=\"token punctuation\">)</span> ≈ <span class=\"token number\">0.19</span> <span class=\"token punctuation\">(</span><span class=\"token number\">19</span><span class=\"token operator\">%</span><span class=\"token punctuation\">)</span>\n<span class=\"token string\">\"stormy\"</span> → exp<span class=\"token punctuation\">(</span>log<span class=\"token punctuation\">(</span><span class=\"token number\">0.05</span><span class=\"token punctuation\">)</span><span class=\"token operator\">/</span><span class=\"token number\">2.0</span><span class=\"token punctuation\">)</span> ≈ <span class=\"token number\">0.11</span> <span class=\"token punctuation\">(</span><span class=\"token number\">11</span><span class=\"token operator\">%</span><span class=\"token punctuation\">)</span></code></pre></div>\n<p>Notice how the probabilities are much closer together now. The model is more likely to choose lower-probability tokens, leading to more diverse and potentially surprising outputs. This setting works for:</p>\n<ul>\n<li>Brainstorming sessions</li>\n<li>Poetry generation</li>\n<li>Exploring alternative perspectives</li>\n</ul>\n<h3 id=\"visualizing-the-impact\" style=\"position:relative;\"><a href=\"#visualizing-the-impact\" aria-label=\"visualizing the impact permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Visualizing the Impact</h3>\n<p>To understand the mathematical transformation more deeply, let’s look at what happens to probability ratios. Consider the ratio between “sunny” and “stormy” at different temperatures:</p>\n<p>Original ratio: 0.50/0.05 = 10:1</p>\n<ul>\n<li>At T=0.5: 0.70/0.01 ≈ 70:1 (more extreme)</li>\n<li>At T=1.0: 0.50/0.05 = 10:1 (unchanged)</li>\n<li>At T=2.0: 0.35/0.11 ≈ 3.2:1 (more balanced)</li>\n</ul>\n<p>This demonstrates how temperature controls the “sharpness” of the probability distribution. Lower temperatures amplify differences between probabilities, while higher temperatures smooth them out.</p>\n<h2 id=\"top-p-sampling-a-more-nuanced-approach\" style=\"position:relative;\"><a href=\"#top-p-sampling-a-more-nuanced-approach\" aria-label=\"top p sampling a more nuanced approach permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Top-p Sampling: A More Nuanced Approach</h2>\n<p>While temperature modifies the entire probability distribution, top-p sampling (also known as nucleus sampling) takes a different approach. Let’s explore this through detailed examples to understand how it works in practice.</p>\n<h3 id=\"understanding-top-p-through-examples\" style=\"position:relative;\"><a href=\"#understanding-top-p-through-examples\" aria-label=\"understanding top p through examples permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Understanding Top-p Through Examples</h3>\n<p>Let’s consider an LLM generating the next word for the prompt “The capital of France is”. Here’s our initial probability distribution:</p>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\">Initial probabilities<span class=\"token punctuation\">:</span>\n<span class=\"token string\">\"Paris\"</span> → <span class=\"token number\">0.60</span>\n<span class=\"token string\">\"Lyon\"</span> → <span class=\"token number\">0.15</span>\n<span class=\"token string\">\"Marseille\"</span> → <span class=\"token number\">0.10</span>\n<span class=\"token string\">\"London\"</span> → <span class=\"token number\">0.05</span>\n<span class=\"token string\">\"Berlin\"</span> → <span class=\"token number\">0.04</span>\n<span class=\"token string\">\"Madrid\"</span> → <span class=\"token number\">0.03</span>\n<span class=\"token string\">\"Rome\"</span> → <span class=\"token number\">0.02</span>\n<span class=\"token string\">\"Other tokens\"</span> → <span class=\"token number\">0.01</span></code></pre></div>\n<p>Let’s see how different top-p values affect token selection:</p>\n<h3 id=\"top-p--09-standard-setting\" style=\"position:relative;\"><a href=\"#top-p--09-standard-setting\" aria-label=\"top p  09 standard setting permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Top-p = 0.9 (Standard Setting)</h3>\n<p>Let’s walk through the calculation:</p>\n<ol>\n<li>Sort by probability (already done above)</li>\n<li>Calculate cumulative probabilities:</li>\n</ol>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token string\">\"Paris\"</span> → <span class=\"token number\">0.60</span> <span class=\"token punctuation\">(</span>cumulative<span class=\"token punctuation\">:</span> <span class=\"token number\">0.60</span><span class=\"token punctuation\">)</span>\n<span class=\"token string\">\"Lyon\"</span> → <span class=\"token number\">0.15</span> <span class=\"token punctuation\">(</span>cumulative<span class=\"token punctuation\">:</span> <span class=\"token number\">0.75</span><span class=\"token punctuation\">)</span>\n<span class=\"token string\">\"Marseille\"</span> → <span class=\"token number\">0.10</span> <span class=\"token punctuation\">(</span>cumulative<span class=\"token punctuation\">:</span> <span class=\"token number\">0.85</span><span class=\"token punctuation\">)</span>\n<span class=\"token string\">\"London\"</span> → <span class=\"token number\">0.05</span> <span class=\"token punctuation\">(</span>cumulative<span class=\"token punctuation\">:</span> <span class=\"token number\">0.90</span><span class=\"token punctuation\">)</span> ← Cutoff point\n<span class=\"token string\">\"Berlin\"</span> → <span class=\"token number\">0.04</span> <span class=\"token punctuation\">(</span>excluded<span class=\"token punctuation\">)</span>\n<span class=\"token string\">\"Madrid\"</span> → <span class=\"token number\">0.03</span> <span class=\"token punctuation\">(</span>excluded<span class=\"token punctuation\">)</span>\n<span class=\"token string\">\"Rome\"</span> → <span class=\"token number\">0.02</span> <span class=\"token punctuation\">(</span>excluded<span class=\"token punctuation\">)</span>\n<span class=\"token string\">\"Other tokens\"</span> → <span class=\"token number\">0.01</span> <span class=\"token punctuation\">(</span>excluded<span class=\"token punctuation\">)</span></code></pre></div>\n<p>The model will only sample from the first four tokens, maintaining their relative probabilities. To get the final sampling probabilities, we renormalize within our selected tokens:</p>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\">Final sampling probabilities<span class=\"token punctuation\">:</span>\n<span class=\"token string\">\"Paris\"</span> → <span class=\"token number\">0.60</span><span class=\"token operator\">/</span><span class=\"token number\">0.90</span> ≈ <span class=\"token number\">0.667</span> <span class=\"token punctuation\">(</span><span class=\"token number\">66.7</span><span class=\"token operator\">%</span><span class=\"token punctuation\">)</span>\n<span class=\"token string\">\"Lyon\"</span> → <span class=\"token number\">0.15</span><span class=\"token operator\">/</span><span class=\"token number\">0.90</span> ≈ <span class=\"token number\">0.167</span> <span class=\"token punctuation\">(</span><span class=\"token number\">16.7</span><span class=\"token operator\">%</span><span class=\"token punctuation\">)</span>\n<span class=\"token string\">\"Marseille\"</span> → <span class=\"token number\">0.10</span><span class=\"token operator\">/</span><span class=\"token number\">0.90</span> ≈ <span class=\"token number\">0.111</span> <span class=\"token punctuation\">(</span><span class=\"token number\">11.1</span><span class=\"token operator\">%</span><span class=\"token punctuation\">)</span>\n<span class=\"token string\">\"London\"</span> → <span class=\"token number\">0.05</span><span class=\"token operator\">/</span><span class=\"token number\">0.90</span> ≈ <span class=\"token number\">0.056</span> <span class=\"token punctuation\">(</span><span class=\"token number\">5.5</span><span class=\"token operator\">%</span><span class=\"token punctuation\">)</span></code></pre></div>\n<h3 id=\"top-p--075-more-conservative\" style=\"position:relative;\"><a href=\"#top-p--075-more-conservative\" aria-label=\"top p  075 more conservative permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Top-p = 0.75 (More Conservative)</h3>\n<p>Let’s see a more restrictive setting:</p>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token string\">\"Paris\"</span> → <span class=\"token number\">0.60</span> <span class=\"token punctuation\">(</span>cumulative<span class=\"token punctuation\">:</span> <span class=\"token number\">0.60</span><span class=\"token punctuation\">)</span>\n<span class=\"token string\">\"Lyon\"</span> → <span class=\"token number\">0.15</span> <span class=\"token punctuation\">(</span>cumulative<span class=\"token punctuation\">:</span> <span class=\"token number\">0.75</span><span class=\"token punctuation\">)</span> ← Cutoff point\n<span class=\"token string\">\"Marseille\"</span> → <span class=\"token number\">0.10</span> <span class=\"token punctuation\">(</span>excluded<span class=\"token punctuation\">)</span>\n<span class=\"token punctuation\">[</span>remaining tokens excluded<span class=\"token punctuation\">]</span>\n\nFinal sampling probabilities<span class=\"token punctuation\">:</span>\n<span class=\"token string\">\"Paris\"</span> → <span class=\"token number\">0.60</span><span class=\"token operator\">/</span><span class=\"token number\">0.75</span> <span class=\"token operator\">=</span> <span class=\"token number\">0.80</span> <span class=\"token punctuation\">(</span><span class=\"token number\">80</span><span class=\"token operator\">%</span><span class=\"token punctuation\">)</span>\n<span class=\"token string\">\"Lyon\"</span> → <span class=\"token number\">0.15</span><span class=\"token operator\">/</span><span class=\"token number\">0.75</span> <span class=\"token operator\">=</span> <span class=\"token number\">0.20</span> <span class=\"token punctuation\">(</span><span class=\"token number\">20</span><span class=\"token operator\">%</span><span class=\"token punctuation\">)</span></code></pre></div>\n<p>Notice how this makes the model more likely to choose “Paris” compared to the 0.9 setting.</p>\n<h3 id=\"top-p--050-highly-conservative\" style=\"position:relative;\"><a href=\"#top-p--050-highly-conservative\" aria-label=\"top p  050 highly conservative permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Top-p = 0.50 (Highly Conservative)</h3>\n<p>In this case:</p>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token string\">\"Paris\"</span> → <span class=\"token number\">0.60</span> <span class=\"token punctuation\">(</span>cumulative<span class=\"token punctuation\">:</span> <span class=\"token number\">0.60</span><span class=\"token punctuation\">)</span> ← Cutoff point exceeded\n<span class=\"token punctuation\">[</span><span class=\"token builtin\">all</span> other tokens excluded<span class=\"token punctuation\">]</span>\n\nFinal sampling probabilities<span class=\"token punctuation\">:</span>\n<span class=\"token string\">\"Paris\"</span> → <span class=\"token number\">1.0</span> <span class=\"token punctuation\">(</span><span class=\"token number\">100</span><span class=\"token operator\">%</span><span class=\"token punctuation\">)</span></code></pre></div>\n<p>This becomes equivalent to greedy sampling since only the highest-probability token makes it into our sampling pool.</p>\n<h3 id=\"combining-temperature-and-top-p\" style=\"position:relative;\"><a href=\"#combining-temperature-and-top-p\" aria-label=\"combining temperature and top p permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Combining Temperature and Top-p</h3>\n<p>When using both parameters, the order of operations matters:</p>\n<ol>\n<li>First, apply temperature to modify the initial distribution</li>\n<li>Then, apply top-p sampling to the modified distribution</li>\n</ol>\n<p>Let’s see an example with temperature = 2.0 and top-p = 0.9:</p>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\">Original → After Temperature → After Top<span class=\"token operator\">-</span>p <span class=\"token punctuation\">(</span>cumulative<span class=\"token punctuation\">)</span>\n<span class=\"token string\">\"Paris\"</span><span class=\"token punctuation\">:</span> <span class=\"token number\">0.60</span> → <span class=\"token number\">0.35</span> → <span class=\"token number\">0.35</span> <span class=\"token punctuation\">(</span><span class=\"token number\">0.35</span><span class=\"token punctuation\">)</span>\n<span class=\"token string\">\"Lyon\"</span><span class=\"token punctuation\">:</span> <span class=\"token number\">0.15</span> → <span class=\"token number\">0.19</span> → <span class=\"token number\">0.19</span> <span class=\"token punctuation\">(</span><span class=\"token number\">0.54</span><span class=\"token punctuation\">)</span>\n<span class=\"token string\">\"Marseille\"</span><span class=\"token punctuation\">:</span> <span class=\"token number\">0.10</span> → <span class=\"token number\">0.15</span> → <span class=\"token number\">0.15</span> <span class=\"token punctuation\">(</span><span class=\"token number\">0.69</span><span class=\"token punctuation\">)</span>\n<span class=\"token string\">\"London\"</span><span class=\"token punctuation\">:</span> <span class=\"token number\">0.05</span> → <span class=\"token number\">0.11</span> → <span class=\"token number\">0.11</span> <span class=\"token punctuation\">(</span><span class=\"token number\">0.80</span><span class=\"token punctuation\">)</span>\n<span class=\"token string\">\"Berlin\"</span><span class=\"token punctuation\">:</span> <span class=\"token number\">0.04</span> → <span class=\"token number\">0.09</span> → <span class=\"token number\">0.09</span> <span class=\"token punctuation\">(</span><span class=\"token number\">0.89</span><span class=\"token punctuation\">)</span>\n<span class=\"token string\">\"Madrid\"</span><span class=\"token punctuation\">:</span> <span class=\"token number\">0.03</span> → <span class=\"token number\">0.07</span> → <span class=\"token number\">0.01</span> <span class=\"token punctuation\">(</span><span class=\"token number\">0.90</span><span class=\"token punctuation\">)</span>\n<span class=\"token punctuation\">[</span>remaining tokens excluded<span class=\"token punctuation\">]</span></code></pre></div>\n<p>This demonstrates how temperature can first flatten the distribution, allowing more tokens to be included in the top-p sampling pool, leading to more diverse outputs while still maintaining coherence.</p>\n<h3 id=\"key-advantages-of-top-p-sampling\" style=\"position:relative;\"><a href=\"#key-advantages-of-top-p-sampling\" aria-label=\"key advantages of top p sampling permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Key Advantages of Top-p Sampling</h3>\n<p>This approach offers several benefits:</p>\n<ul>\n<li>Dynamically adapts to the model’s confidence (uses fewer tokens when the model is very confident)</li>\n<li>Prevents sampling from the long tail of very unlikely tokens</li>\n<li>Maintains coherence while allowing appropriate levels of creativity</li>\n<li>Computationally efficient since we only need to consider a subset of tokens</li>\n</ul>\n<h2 id=\"practical-implications-when-to-use-what\" style=\"position:relative;\"><a href=\"#practical-implications-when-to-use-what\" aria-label=\"practical implications when to use what permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Practical Implications: When to Use What?</h2>\n<p>The choice between temperature and top-p sampling (or using both) depends on your specific use case:</p>\n<h3 id=\"high-precision-tasks\" style=\"position:relative;\"><a href=\"#high-precision-tasks\" aria-label=\"high precision tasks permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>High-Precision Tasks</h3>\n<p>For tasks requiring accuracy and consistency:</p>\n<ul>\n<li>Temperature: 0.0-0.3</li>\n<li>Top-p: 0.1-0.3</li>\n</ul>\n<p>Example use cases: Code generation, factual Q&#x26;A, structured data generation</p>\n<h3 id=\"balanced-generation\" style=\"position:relative;\"><a href=\"#balanced-generation\" aria-label=\"balanced generation permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Balanced Generation</h3>\n<p>For general-purpose text generation:</p>\n<ul>\n<li>Temperature: 0.7-0.9</li>\n<li>Top-p: 0.9</li>\n</ul>\n<p>Example use cases: Chat responses, content generation, summarization</p>\n<h3 id=\"creative-tasks\" style=\"position:relative;\"><a href=\"#creative-tasks\" aria-label=\"creative tasks permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Creative Tasks</h3>\n<p>For maximizing creativity:</p>\n<ul>\n<li>Temperature: 1.0-1.5</li>\n<li>Top-p: 0.95-1.0</li>\n</ul>\n<p>Example use cases: Storytelling, poetry, ideation</p>\n<h2 id=\"common-pitfalls-and-best-practices\" style=\"position:relative;\"><a href=\"#common-pitfalls-and-best-practices\" aria-label=\"common pitfalls and best practices permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Common Pitfalls and Best Practices</h2>\n<ol>\n<li>\n<p><strong>Avoiding Extreme Values</strong></p>\n<ul>\n<li>Very high temperatures (>1.5) often produce gibberish</li>\n<li>Extremely low top-p values (&#x3C;0.1) can make outputs too restrictive</li>\n</ul>\n</li>\n<li>\n<p><strong>Combining Parameters</strong>\nWhen using both temperature and top-p:</p>\n<ul>\n<li>Apply temperature first to modify the distribution</li>\n<li>Then apply top-p sampling to the modified distribution</li>\n<li>Be careful not to be too restrictive with both parameters</li>\n</ul>\n</li>\n<li>\n<p><strong>Context Sensitivity</strong></p>\n<ul>\n<li>Different parts of your application might benefit from different sampling settings</li>\n<li>Consider dynamically adjusting parameters based on the context or user needs</li>\n</ul>\n</li>\n</ol>\n<h2 id=\"implementation-examples\" style=\"position:relative;\"><a href=\"#implementation-examples\" aria-label=\"implementation examples permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Implementation Examples</h2>\n<p>Let’s implement both temperature and top-p sampling in Python, with detailed examples showing how they transform probability distributions. We’ll start with some utility functions and then implement each sampling method.</p>\n<h3 id=\"utility-functions\" style=\"position:relative;\"><a href=\"#utility-functions\" aria-label=\"utility functions permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Utility Functions</h3>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token keyword\">import</span> numpy <span class=\"token keyword\">as</span> np\n<span class=\"token keyword\">from</span> typing <span class=\"token keyword\">import</span> List<span class=\"token punctuation\">,</span> Dict<span class=\"token punctuation\">,</span> Tuple\n\n<span class=\"token keyword\">def</span> <span class=\"token function\">softmax</span><span class=\"token punctuation\">(</span>logits<span class=\"token punctuation\">:</span> np<span class=\"token punctuation\">.</span>ndarray<span class=\"token punctuation\">)</span> <span class=\"token operator\">-</span><span class=\"token operator\">></span> np<span class=\"token punctuation\">.</span>ndarray<span class=\"token punctuation\">:</span>\n    <span class=\"token triple-quoted-string string\">\"\"\"\n    Convert logits to probabilities using softmax function.\n    \n    Args:\n        logits (np.ndarray): Raw logit scores from the model\n    \n    Returns:\n        np.ndarray: Probability distribution summing to 1\n    \"\"\"</span>\n    exp_logits <span class=\"token operator\">=</span> np<span class=\"token punctuation\">.</span>exp<span class=\"token punctuation\">(</span>logits <span class=\"token operator\">-</span> np<span class=\"token punctuation\">.</span><span class=\"token builtin\">max</span><span class=\"token punctuation\">(</span>logits<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>  <span class=\"token comment\"># Subtract max for numerical stability</span>\n    <span class=\"token keyword\">return</span> exp_logits <span class=\"token operator\">/</span> exp_logits<span class=\"token punctuation\">.</span><span class=\"token builtin\">sum</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n\n<span class=\"token keyword\">def</span> <span class=\"token function\">create_vocab_distribution</span><span class=\"token punctuation\">(</span>vocab<span class=\"token punctuation\">:</span> List<span class=\"token punctuation\">[</span><span class=\"token builtin\">str</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">,</span> probs<span class=\"token punctuation\">:</span> List<span class=\"token punctuation\">[</span><span class=\"token builtin\">float</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span> <span class=\"token operator\">-</span><span class=\"token operator\">></span> Dict<span class=\"token punctuation\">[</span><span class=\"token builtin\">str</span><span class=\"token punctuation\">,</span> <span class=\"token builtin\">float</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">:</span>\n    <span class=\"token triple-quoted-string string\">\"\"\"\n    Create a dictionary mapping vocabulary tokens to their probabilities.\n    \n    Args:\n        vocab (List[str]): List of tokens\n        probs (List[float]): Corresponding probabilities\n        \n    Returns:\n        Dict[str, float]: Mapping of tokens to probabilities\n    \"\"\"</span>\n    <span class=\"token keyword\">return</span> <span class=\"token builtin\">dict</span><span class=\"token punctuation\">(</span><span class=\"token builtin\">zip</span><span class=\"token punctuation\">(</span>vocab<span class=\"token punctuation\">,</span> probs<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span></code></pre></div>\n<h3 id=\"temperature-sampling-implementation\" style=\"position:relative;\"><a href=\"#temperature-sampling-implementation\" aria-label=\"temperature sampling implementation permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Temperature Sampling Implementation</h3>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token keyword\">def</span> <span class=\"token function\">apply_temperature</span><span class=\"token punctuation\">(</span>\n    probs<span class=\"token punctuation\">:</span> Dict<span class=\"token punctuation\">[</span><span class=\"token builtin\">str</span><span class=\"token punctuation\">,</span> <span class=\"token builtin\">float</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">,</span> \n    temperature<span class=\"token punctuation\">:</span> <span class=\"token builtin\">float</span>\n<span class=\"token punctuation\">)</span> <span class=\"token operator\">-</span><span class=\"token operator\">></span> Dict<span class=\"token punctuation\">[</span><span class=\"token builtin\">str</span><span class=\"token punctuation\">,</span> <span class=\"token builtin\">float</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">:</span>\n    <span class=\"token triple-quoted-string string\">\"\"\"\n    Apply temperature scaling to a probability distribution.\n    \n    Args:\n        probs (Dict[str, float]): Original token probabilities\n        temperature (float): Temperature parameter (> 0)\n        \n    Returns:\n        Dict[str, float]: Modified probability distribution\n    \"\"\"</span>\n    <span class=\"token keyword\">if</span> temperature <span class=\"token operator\">==</span> <span class=\"token number\">0</span><span class=\"token punctuation\">:</span>\n        <span class=\"token comment\"># For temperature 0, return 1.0 for highest prob token, 0 for others</span>\n        max_token <span class=\"token operator\">=</span> <span class=\"token builtin\">max</span><span class=\"token punctuation\">(</span>probs<span class=\"token punctuation\">.</span>items<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span> key<span class=\"token operator\">=</span><span class=\"token keyword\">lambda</span> x<span class=\"token punctuation\">:</span> x<span class=\"token punctuation\">[</span><span class=\"token number\">1</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">[</span><span class=\"token number\">0</span><span class=\"token punctuation\">]</span>\n        <span class=\"token keyword\">return</span> <span class=\"token punctuation\">{</span>token<span class=\"token punctuation\">:</span> <span class=\"token builtin\">float</span><span class=\"token punctuation\">(</span>token <span class=\"token operator\">==</span> max_token<span class=\"token punctuation\">)</span> <span class=\"token keyword\">for</span> token <span class=\"token keyword\">in</span> probs<span class=\"token punctuation\">}</span>\n    \n    <span class=\"token comment\"># Convert probabilities to log space</span>\n    log_probs <span class=\"token operator\">=</span> <span class=\"token punctuation\">{</span>token<span class=\"token punctuation\">:</span> np<span class=\"token punctuation\">.</span>log<span class=\"token punctuation\">(</span>p<span class=\"token punctuation\">)</span> <span class=\"token keyword\">for</span> token<span class=\"token punctuation\">,</span> p <span class=\"token keyword\">in</span> probs<span class=\"token punctuation\">.</span>items<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">}</span>\n    \n    <span class=\"token comment\"># Apply temperature scaling</span>\n    scaled_log_probs <span class=\"token operator\">=</span> <span class=\"token punctuation\">{</span>token<span class=\"token punctuation\">:</span> lp <span class=\"token operator\">/</span> temperature <span class=\"token keyword\">for</span> token<span class=\"token punctuation\">,</span> lp <span class=\"token keyword\">in</span> log_probs<span class=\"token punctuation\">.</span>items<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">}</span>\n    \n    <span class=\"token comment\"># Convert back to probabilities</span>\n    max_log_p <span class=\"token operator\">=</span> <span class=\"token builtin\">max</span><span class=\"token punctuation\">(</span>scaled_log_probs<span class=\"token punctuation\">.</span>values<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>  <span class=\"token comment\"># For numerical stability</span>\n    exp_probs <span class=\"token operator\">=</span> <span class=\"token punctuation\">{</span>\n        token<span class=\"token punctuation\">:</span> np<span class=\"token punctuation\">.</span>exp<span class=\"token punctuation\">(</span>lp <span class=\"token operator\">-</span> max_log_p<span class=\"token punctuation\">)</span> \n        <span class=\"token keyword\">for</span> token<span class=\"token punctuation\">,</span> lp <span class=\"token keyword\">in</span> scaled_log_probs<span class=\"token punctuation\">.</span>items<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n    <span class=\"token punctuation\">}</span>\n    \n    <span class=\"token comment\"># Normalize to get final probabilities</span>\n    normalization <span class=\"token operator\">=</span> <span class=\"token builtin\">sum</span><span class=\"token punctuation\">(</span>exp_probs<span class=\"token punctuation\">.</span>values<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n    <span class=\"token keyword\">return</span> <span class=\"token punctuation\">{</span>token<span class=\"token punctuation\">:</span> p <span class=\"token operator\">/</span> normalization <span class=\"token keyword\">for</span> token<span class=\"token punctuation\">,</span> p <span class=\"token keyword\">in</span> exp_probs<span class=\"token punctuation\">.</span>items<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">}</span>\n\n<span class=\"token comment\"># Example usage:</span>\nvocab <span class=\"token operator\">=</span> <span class=\"token punctuation\">[</span><span class=\"token string\">\"Paris\"</span><span class=\"token punctuation\">,</span> <span class=\"token string\">\"Lyon\"</span><span class=\"token punctuation\">,</span> <span class=\"token string\">\"Marseille\"</span><span class=\"token punctuation\">,</span> <span class=\"token string\">\"London\"</span><span class=\"token punctuation\">,</span> <span class=\"token string\">\"Berlin\"</span><span class=\"token punctuation\">]</span>\nprobs <span class=\"token operator\">=</span> <span class=\"token punctuation\">[</span><span class=\"token number\">0.6</span><span class=\"token punctuation\">,</span> <span class=\"token number\">0.15</span><span class=\"token punctuation\">,</span> <span class=\"token number\">0.1</span><span class=\"token punctuation\">,</span> <span class=\"token number\">0.05</span><span class=\"token punctuation\">,</span> <span class=\"token number\">0.1</span><span class=\"token punctuation\">]</span>\ndistribution <span class=\"token operator\">=</span> create_vocab_distribution<span class=\"token punctuation\">(</span>vocab<span class=\"token punctuation\">,</span> probs<span class=\"token punctuation\">)</span>\n\n<span class=\"token comment\"># Try different temperatures</span>\ntemperatures <span class=\"token operator\">=</span> <span class=\"token punctuation\">[</span><span class=\"token number\">0.5</span><span class=\"token punctuation\">,</span> <span class=\"token number\">1.0</span><span class=\"token punctuation\">,</span> <span class=\"token number\">2.0</span><span class=\"token punctuation\">]</span>\n<span class=\"token keyword\">for</span> temp <span class=\"token keyword\">in</span> temperatures<span class=\"token punctuation\">:</span>\n    modified <span class=\"token operator\">=</span> apply_temperature<span class=\"token punctuation\">(</span>distribution<span class=\"token punctuation\">,</span> temp<span class=\"token punctuation\">)</span>\n    <span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string-interpolation\"><span class=\"token string\">f\"\\nTemperature </span><span class=\"token interpolation\"><span class=\"token punctuation\">{</span>temp<span class=\"token punctuation\">}</span></span><span class=\"token string\">:\"</span></span><span class=\"token punctuation\">)</span>\n    <span class=\"token keyword\">for</span> token<span class=\"token punctuation\">,</span> prob <span class=\"token keyword\">in</span> modified<span class=\"token punctuation\">.</span>items<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n        <span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string-interpolation\"><span class=\"token string\">f\"</span><span class=\"token interpolation\"><span class=\"token punctuation\">{</span>token<span class=\"token punctuation\">}</span></span><span class=\"token string\">: </span><span class=\"token interpolation\"><span class=\"token punctuation\">{</span>prob<span class=\"token punctuation\">:</span><span class=\"token format-spec\">.3f</span><span class=\"token punctuation\">}</span></span><span class=\"token string\">\"</span></span><span class=\"token punctuation\">)</span></code></pre></div>\n<h3 id=\"top-p-nucleus-sampling-implementation\" style=\"position:relative;\"><a href=\"#top-p-nucleus-sampling-implementation\" aria-label=\"top p nucleus sampling implementation permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Top-p (Nucleus) Sampling Implementation</h3>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token keyword\">def</span> <span class=\"token function\">apply_top_p</span><span class=\"token punctuation\">(</span>\n    probs<span class=\"token punctuation\">:</span> Dict<span class=\"token punctuation\">[</span><span class=\"token builtin\">str</span><span class=\"token punctuation\">,</span> <span class=\"token builtin\">float</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">,</span> \n    p<span class=\"token punctuation\">:</span> <span class=\"token builtin\">float</span>\n<span class=\"token punctuation\">)</span> <span class=\"token operator\">-</span><span class=\"token operator\">></span> Dict<span class=\"token punctuation\">[</span><span class=\"token builtin\">str</span><span class=\"token punctuation\">,</span> <span class=\"token builtin\">float</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">:</span>\n    <span class=\"token triple-quoted-string string\">\"\"\"\n    Apply top-p (nucleus) sampling to a probability distribution.\n    \n    Args:\n        probs (Dict[str, float]): Original token probabilities\n        p (float): Cumulative probability threshold (0 &lt; p ≤ 1)\n        \n    Returns:\n        Dict[str, float]: Modified probability distribution\n    \"\"\"</span>\n    <span class=\"token comment\"># Sort tokens by probability</span>\n    sorted_probs <span class=\"token operator\">=</span> <span class=\"token builtin\">sorted</span><span class=\"token punctuation\">(</span>\n        probs<span class=\"token punctuation\">.</span>items<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span> \n        key<span class=\"token operator\">=</span><span class=\"token keyword\">lambda</span> x<span class=\"token punctuation\">:</span> x<span class=\"token punctuation\">[</span><span class=\"token number\">1</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">,</span> \n        reverse<span class=\"token operator\">=</span><span class=\"token boolean\">True</span>\n    <span class=\"token punctuation\">)</span>\n    \n    <span class=\"token comment\"># Calculate cumulative probabilities</span>\n    cumulative <span class=\"token operator\">=</span> <span class=\"token number\">0</span>\n    keep_tokens <span class=\"token operator\">=</span> <span class=\"token punctuation\">[</span><span class=\"token punctuation\">]</span>\n    <span class=\"token keyword\">for</span> token<span class=\"token punctuation\">,</span> prob <span class=\"token keyword\">in</span> sorted_probs<span class=\"token punctuation\">:</span>\n        cumulative <span class=\"token operator\">+=</span> prob\n        keep_tokens<span class=\"token punctuation\">.</span>append<span class=\"token punctuation\">(</span>token<span class=\"token punctuation\">)</span>\n        <span class=\"token keyword\">if</span> cumulative <span class=\"token operator\">>=</span> p<span class=\"token punctuation\">:</span>\n            <span class=\"token keyword\">break</span>\n    \n    <span class=\"token comment\"># Create new distribution with only selected tokens</span>\n    new_probs <span class=\"token operator\">=</span> <span class=\"token punctuation\">{</span>\n        token<span class=\"token punctuation\">:</span> probs<span class=\"token punctuation\">[</span>token<span class=\"token punctuation\">]</span> <span class=\"token keyword\">for</span> token <span class=\"token keyword\">in</span> keep_tokens\n    <span class=\"token punctuation\">}</span>\n    \n    <span class=\"token comment\"># Renormalize probabilities</span>\n    normalization <span class=\"token operator\">=</span> <span class=\"token builtin\">sum</span><span class=\"token punctuation\">(</span>new_probs<span class=\"token punctuation\">.</span>values<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n    <span class=\"token keyword\">return</span> <span class=\"token punctuation\">{</span>\n        token<span class=\"token punctuation\">:</span> prob <span class=\"token operator\">/</span> normalization \n        <span class=\"token keyword\">for</span> token<span class=\"token punctuation\">,</span> prob <span class=\"token keyword\">in</span> new_probs<span class=\"token punctuation\">.</span>items<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n    <span class=\"token punctuation\">}</span>\n\n<span class=\"token comment\"># Example usage:</span>\np_values <span class=\"token operator\">=</span> <span class=\"token punctuation\">[</span><span class=\"token number\">0.9</span><span class=\"token punctuation\">,</span> <span class=\"token number\">0.75</span><span class=\"token punctuation\">,</span> <span class=\"token number\">0.5</span><span class=\"token punctuation\">]</span>\n<span class=\"token keyword\">for</span> p <span class=\"token keyword\">in</span> p_values<span class=\"token punctuation\">:</span>\n    modified <span class=\"token operator\">=</span> apply_top_p<span class=\"token punctuation\">(</span>distribution<span class=\"token punctuation\">,</span> p<span class=\"token punctuation\">)</span>\n    <span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string-interpolation\"><span class=\"token string\">f\"\\nTop-p </span><span class=\"token interpolation\"><span class=\"token punctuation\">{</span>p<span class=\"token punctuation\">}</span></span><span class=\"token string\">:\"</span></span><span class=\"token punctuation\">)</span>\n    <span class=\"token keyword\">for</span> token<span class=\"token punctuation\">,</span> prob <span class=\"token keyword\">in</span> modified<span class=\"token punctuation\">.</span>items<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n        <span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string-interpolation\"><span class=\"token string\">f\"</span><span class=\"token interpolation\"><span class=\"token punctuation\">{</span>token<span class=\"token punctuation\">}</span></span><span class=\"token string\">: </span><span class=\"token interpolation\"><span class=\"token punctuation\">{</span>prob<span class=\"token punctuation\">:</span><span class=\"token format-spec\">.3f</span><span class=\"token punctuation\">}</span></span><span class=\"token string\">\"</span></span><span class=\"token punctuation\">)</span></code></pre></div>\n<h3 id=\"combining-temperature-and-top-p-1\" style=\"position:relative;\"><a href=\"#combining-temperature-and-top-p-1\" aria-label=\"combining temperature and top p 1 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Combining Temperature and Top-p</h3>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token keyword\">def</span> <span class=\"token function\">sample_token</span><span class=\"token punctuation\">(</span>\n    probs<span class=\"token punctuation\">:</span> Dict<span class=\"token punctuation\">[</span><span class=\"token builtin\">str</span><span class=\"token punctuation\">,</span> <span class=\"token builtin\">float</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">,</span> \n    temperature<span class=\"token punctuation\">:</span> <span class=\"token builtin\">float</span> <span class=\"token operator\">=</span> <span class=\"token number\">1.0</span><span class=\"token punctuation\">,</span> \n    top_p<span class=\"token punctuation\">:</span> <span class=\"token builtin\">float</span> <span class=\"token operator\">=</span> <span class=\"token number\">1.0</span>\n<span class=\"token punctuation\">)</span> <span class=\"token operator\">-</span><span class=\"token operator\">></span> <span class=\"token builtin\">str</span><span class=\"token punctuation\">:</span>\n    <span class=\"token triple-quoted-string string\">\"\"\"\n    Sample a token using both temperature and top-p sampling.\n    \n    Args:\n        probs (Dict[str, float]): Original token probabilities\n        temperature (float): Temperature parameter (> 0)\n        top_p (float): Cumulative probability threshold (0 &lt; p ≤ 1)\n        \n    Returns:\n        str: Sampled token\n    \"\"\"</span>\n    <span class=\"token comment\"># First apply temperature</span>\n    temp_probs <span class=\"token operator\">=</span> apply_temperature<span class=\"token punctuation\">(</span>probs<span class=\"token punctuation\">,</span> temperature<span class=\"token punctuation\">)</span>\n    \n    <span class=\"token comment\"># Then apply top-p</span>\n    final_probs <span class=\"token operator\">=</span> apply_top_p<span class=\"token punctuation\">(</span>temp_probs<span class=\"token punctuation\">,</span> top_p<span class=\"token punctuation\">)</span>\n    \n    <span class=\"token comment\"># Sample from the final distribution</span>\n    tokens <span class=\"token operator\">=</span> <span class=\"token builtin\">list</span><span class=\"token punctuation\">(</span>final_probs<span class=\"token punctuation\">.</span>keys<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n    probabilities <span class=\"token operator\">=</span> <span class=\"token builtin\">list</span><span class=\"token punctuation\">(</span>final_probs<span class=\"token punctuation\">.</span>values<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n    <span class=\"token keyword\">return</span> np<span class=\"token punctuation\">.</span>random<span class=\"token punctuation\">.</span>choice<span class=\"token punctuation\">(</span>tokens<span class=\"token punctuation\">,</span> p<span class=\"token operator\">=</span>probabilities<span class=\"token punctuation\">)</span>\n\n<span class=\"token comment\"># Example usage showing multiple samples:</span>\n<span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string\">\"\\nSampling with temperature=0.8 and top_p=0.9:\"</span><span class=\"token punctuation\">)</span>\n<span class=\"token keyword\">for</span> _ <span class=\"token keyword\">in</span> <span class=\"token builtin\">range</span><span class=\"token punctuation\">(</span><span class=\"token number\">5</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n    token <span class=\"token operator\">=</span> sample_token<span class=\"token punctuation\">(</span>distribution<span class=\"token punctuation\">,</span> temperature<span class=\"token operator\">=</span><span class=\"token number\">0.8</span><span class=\"token punctuation\">,</span> top_p<span class=\"token operator\">=</span><span class=\"token number\">0.9</span><span class=\"token punctuation\">)</span>\n    <span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string-interpolation\"><span class=\"token string\">f\"Sampled token: </span><span class=\"token interpolation\"><span class=\"token punctuation\">{</span>token<span class=\"token punctuation\">}</span></span><span class=\"token string\">\"</span></span><span class=\"token punctuation\">)</span></code></pre></div>\n<h3 id=\"putting-it-all-together-a-complete-example\" style=\"position:relative;\"><a href=\"#putting-it-all-together-a-complete-example\" aria-label=\"putting it all together a complete example permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Putting It All Together: A Complete Example</h3>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token keyword\">def</span> <span class=\"token function\">analyze_sampling_parameters</span><span class=\"token punctuation\">(</span>\n    vocab<span class=\"token punctuation\">:</span> List<span class=\"token punctuation\">[</span><span class=\"token builtin\">str</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">,</span>\n    probs<span class=\"token punctuation\">:</span> List<span class=\"token punctuation\">[</span><span class=\"token builtin\">float</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">,</span>\n    temperature<span class=\"token punctuation\">:</span> <span class=\"token builtin\">float</span><span class=\"token punctuation\">,</span>\n    top_p<span class=\"token punctuation\">:</span> <span class=\"token builtin\">float</span><span class=\"token punctuation\">,</span>\n    n_samples<span class=\"token punctuation\">:</span> <span class=\"token builtin\">int</span> <span class=\"token operator\">=</span> <span class=\"token number\">1000</span>\n<span class=\"token punctuation\">)</span> <span class=\"token operator\">-</span><span class=\"token operator\">></span> Dict<span class=\"token punctuation\">[</span><span class=\"token builtin\">str</span><span class=\"token punctuation\">,</span> <span class=\"token builtin\">int</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">:</span>\n    <span class=\"token triple-quoted-string string\">\"\"\"\n    Analyze the effects of sampling parameters by generating multiple samples.\n    \n    Args:\n        vocab (List[str]): List of tokens\n        probs (List[float]): Original probabilities\n        temperature (float): Temperature parameter\n        top_p (float): Top-p threshold\n        n_samples (int): Number of samples to generate\n        \n    Returns:\n        Dict[str, int]: Count of how many times each token was sampled\n    \"\"\"</span>\n    distribution <span class=\"token operator\">=</span> create_vocab_distribution<span class=\"token punctuation\">(</span>vocab<span class=\"token punctuation\">,</span> probs<span class=\"token punctuation\">)</span>\n    samples <span class=\"token operator\">=</span> <span class=\"token punctuation\">[</span>\n        sample_token<span class=\"token punctuation\">(</span>distribution<span class=\"token punctuation\">,</span> temperature<span class=\"token punctuation\">,</span> top_p<span class=\"token punctuation\">)</span>\n        <span class=\"token keyword\">for</span> _ <span class=\"token keyword\">in</span> <span class=\"token builtin\">range</span><span class=\"token punctuation\">(</span>n_samples<span class=\"token punctuation\">)</span>\n    <span class=\"token punctuation\">]</span>\n    <span class=\"token keyword\">return</span> <span class=\"token builtin\">dict</span><span class=\"token punctuation\">(</span>Counter<span class=\"token punctuation\">(</span>samples<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n\n<span class=\"token comment\"># Example usage:</span>\nvocab <span class=\"token operator\">=</span> <span class=\"token punctuation\">[</span><span class=\"token string\">\"Paris\"</span><span class=\"token punctuation\">,</span> <span class=\"token string\">\"Lyon\"</span><span class=\"token punctuation\">,</span> <span class=\"token string\">\"Marseille\"</span><span class=\"token punctuation\">,</span> <span class=\"token string\">\"London\"</span><span class=\"token punctuation\">,</span> <span class=\"token string\">\"Berlin\"</span><span class=\"token punctuation\">]</span>\nprobs <span class=\"token operator\">=</span> <span class=\"token punctuation\">[</span><span class=\"token number\">0.6</span><span class=\"token punctuation\">,</span> <span class=\"token number\">0.15</span><span class=\"token punctuation\">,</span> <span class=\"token number\">0.1</span><span class=\"token punctuation\">,</span> <span class=\"token number\">0.05</span><span class=\"token punctuation\">,</span> <span class=\"token number\">0.1</span><span class=\"token punctuation\">]</span>\n\n<span class=\"token comment\"># Try different parameter combinations</span>\nparameter_sets <span class=\"token operator\">=</span> <span class=\"token punctuation\">[</span>\n    <span class=\"token punctuation\">(</span><span class=\"token number\">1.0</span><span class=\"token punctuation\">,</span> <span class=\"token number\">1.0</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span>  <span class=\"token comment\"># Baseline</span>\n    <span class=\"token punctuation\">(</span><span class=\"token number\">0.5</span><span class=\"token punctuation\">,</span> <span class=\"token number\">1.0</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span>  <span class=\"token comment\"># Lower temperature</span>\n    <span class=\"token punctuation\">(</span><span class=\"token number\">1.0</span><span class=\"token punctuation\">,</span> <span class=\"token number\">0.9</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span>  <span class=\"token comment\"># Top-p only</span>\n    <span class=\"token punctuation\">(</span><span class=\"token number\">0.5</span><span class=\"token punctuation\">,</span> <span class=\"token number\">0.9</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span>  <span class=\"token comment\"># Both</span>\n<span class=\"token punctuation\">]</span>\n\n<span class=\"token keyword\">for</span> temp<span class=\"token punctuation\">,</span> p <span class=\"token keyword\">in</span> parameter_sets<span class=\"token punctuation\">:</span>\n    counts <span class=\"token operator\">=</span> analyze_sampling_parameters<span class=\"token punctuation\">(</span>\n        vocab<span class=\"token punctuation\">,</span> probs<span class=\"token punctuation\">,</span> temp<span class=\"token punctuation\">,</span> p<span class=\"token punctuation\">,</span> n_samples<span class=\"token operator\">=</span><span class=\"token number\">1000</span>\n    <span class=\"token punctuation\">)</span>\n    <span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string-interpolation\"><span class=\"token string\">f\"\\nTemperature=</span><span class=\"token interpolation\"><span class=\"token punctuation\">{</span>temp<span class=\"token punctuation\">}</span></span><span class=\"token string\">, Top-p=</span><span class=\"token interpolation\"><span class=\"token punctuation\">{</span>p<span class=\"token punctuation\">}</span></span><span class=\"token string\">\"</span></span><span class=\"token punctuation\">)</span>\n    <span class=\"token keyword\">for</span> token<span class=\"token punctuation\">,</span> count <span class=\"token keyword\">in</span> counts<span class=\"token punctuation\">.</span>items<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n        <span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string-interpolation\"><span class=\"token string\">f\"</span><span class=\"token interpolation\"><span class=\"token punctuation\">{</span>token<span class=\"token punctuation\">}</span></span><span class=\"token string\">: </span><span class=\"token interpolation\"><span class=\"token punctuation\">{</span>count<span class=\"token operator\">/</span><span class=\"token number\">1000</span><span class=\"token punctuation\">:</span><span class=\"token format-spec\">.3f</span><span class=\"token punctuation\">}</span></span><span class=\"token string\">\"</span></span><span class=\"token punctuation\">)</span></code></pre></div>\n<p>This implementation provides a complete framework for experimenting with temperature and top-p sampling. The code is designed to be educational and includes detailed comments explaining each step. You can use it to:</p>\n<ol>\n<li>Understand how each parameter transforms probabilities</li>\n<li>Visualize the effects of different parameter combinations</li>\n<li>Generate samples to see the practical impact</li>\n<li>Analyze the distribution of sampled tokens</li>\n</ol>\n<p>The example usage sections demonstrate how to use each function and help build intuition about how these parameters affect token selection in practice.</p>\n<h2 id=\"conclusion\" style=\"position:relative;\"><a href=\"#conclusion\" aria-label=\"conclusion permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Conclusion</h2>\n<p>Understanding temperature and top-p sampling is crucial for getting the most out of LLMs. These parameters offer fine-grained control over the balance between creativity and determinism in model outputs. By carefully tuning these parameters based on your specific use case, you can significantly improve the quality and appropriateness of generated content.</p>\n<p>Remember that there’s no one-size-fits-all setting – experimentation is key to finding the right balance for your specific application. Consider creating a systematic testing process to evaluate different parameter combinations for your particular use case.</p>","fields":{"slug":"/posts/2025//llm/understanding-temperature-and-top-p-sampling-in-large-language-models","tagSlugs":["/tag/llm/"]},"frontmatter":{"date":"2025-02-23T20:35:37.121Z","description":"Explore the intricacies of temperature and top-p sampling in Large Language Models, understanding their impact on text generation and practical applications.","tags":["LLM"],"title":"Understanding Temperature and Top-p Sampling in Large Language Models","socialImage":null}}},"pageContext":{"slug":"/posts/2025//llm/understanding-temperature-and-top-p-sampling-in-large-language-models"}},"staticQueryHashes":["251939775","288581551","401334301"]}