{"componentChunkName":"component---src-templates-post-template-post-template-tsx","path":"/posts/DataAnalysis-Scrapy","result":{"data":{"markdownRemark":{"id":"965dc956-a97c-5a4e-9f97-143a1cef55c2","html":"<p>With a colleague at WeCode, which is a coding bootcamp based in Seoul, South Korea, I am doing a data analysis project on the relationship betwen box office and music daily chart. We are trying to see how box office affects what people listen to in their daily lives. Not sure how much correlation there would be, but this would be beneficial.</p>\n<p>#1. What is Scrapy?\nAccording to the official document, <code class=\"language-text\">Scrapy</code> is an application framework for crawling web sites and extracting structured data which can be used for a wide range of useful applications, like data mining, information processing or historical archival.</p>\n<p>#2. Starting a <code class=\"language-text\">Scrapy</code> project\nI intalled <code class=\"language-text\">Scrapy</code> in a virtual environment created with <code class=\"language-text\">Miniconda</code>.</p>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">(bedataproj) pip install scrapy</code></pre></div>\n<p>And created a <code class=\"language-text\">Scrapy</code> project</p>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">(bedataproj) scrapy startproject project_name</code></pre></div>\n<p>A <code class=\"language-text\">genspider</code> command helps create a data crawling spider.</p>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">(bedataproj) scrapy genspider spider_name website</code></pre></div>\n<p>Below is the spider</p>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">##spider.py\n\nimport scrapy\n\nclass MusicSpiderSpider(scrapy.Spider):\n    name = 'music_spider'\n    start_urls = ['http://www.mnet.com/chart/TOP100/20190623']\n\n    def parse(self, response):\n        top_selector = '.MMLITitle_Box'\n\n        for music in response.css(top_selector):\n            musician = '.MMLITitle_Info .MMLIInfo_Artist ::text'\n            song = '.MMLITitleSong_Box .MMLI_Song ::text'\n            album = '.MMLITitle_Info .MMLIInfo_Album ::text'\n            yield {\n                \"song\" : music.css(song).extract_first(),\n                \"musician\" : music.css(musician).extract_first(),\n                \"album\" : music.css(album).extract_first(),\n            }\n</code></pre></div>\n<p>I will explain each component of the spider. <br></p>\n<ol>\n<li><code class=\"language-text\">name</code> is the name of the spider<br></li>\n<li><code class=\"language-text\">start_urls</code> is the website you would like to crawl your data from <br></li>\n<li><code class=\"language-text\">parse</code> function is how you are going to parse the crawled data</li>\n</ol>\n<p>When you crawl data from a webiste using <code class=\"language-text\">Scrapy</code>, the easiest way is using <code class=\"language-text\">class</code> and/or <code class=\"language-text\">id</code> as if you are applying CSS to HTML.</p>\n<p>Appending <code class=\"language-text\">::text</code> to a selector means that I am going to crawl innerText of the class. <br>\nAnd then I called <code class=\"language-text\">extract_first()</code> on the object returned by <code class=\"language-text\">music.css(selector)</code> because I am extracting the first element that matches the selectorâ€”in case there are more than one.</p>\n<p>Then you run <code class=\"language-text\">Scrapy</code> like below</p>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">scrapy runspider spider_name</code></pre></div>","fields":{"slug":"/posts/2019//posts/DataAnalysis-Scrapy","tagSlugs":["/tag/python/"]},"frontmatter":{"date":"2019-06-21T19:56:37.121Z","description":"Data Analysis project using Scrapy and Luigi","tags":["Python"],"title":"Data Crawling Using Scrapy","socialImage":null}}},"pageContext":{"slug":"/posts/2019//posts/DataAnalysis-Scrapy"}},"staticQueryHashes":["251939775","288581551","401334301"]}