{"componentChunkName":"component---src-templates-category-template-category-template-tsx","path":"/category/llm","result":{"data":{"allMarkdownRemark":{"edges":[{"node":{"fields":{"slug":"/posts/2024//llm/what-is-attention","categorySlug":"/category/llm/"},"frontmatter":{"description":"An exploration of the concept of Attention in LLMs, discussing its significance and impact on model performance and understanding.","category":"LLM","title":"What Is Attention?","date":"2024-11-30T20:35:37.121Z","slug":"/llm/what-is-attention"}}},{"node":{"fields":{"slug":"/posts/2024//llm/why-evaluation-is-important","categorySlug":"/category/llm/"},"frontmatter":{"description":"Exploring the significance of evaluation in developing LLM applications","category":"LLM","title":"Why Is Evaluation Important in Building an LLM Application?","date":"2024-11-21T20:35:37.121Z","slug":"/llm/why-evaluation-is-important"}}},{"node":{"fields":{"slug":"/posts/2024//llm/what-is-direct-parameter-optimization","categorySlug":"/category/llm/"},"frontmatter":{"description":"Investigating whether fine tuning can actually meet our needs","category":"LLM","title":"What Is Direct Parameter Optimization(DPO)?","date":"2024-11-02T20:35:37.121Z","slug":"/llm/what-is-direct-parameter-optimization"}}},{"node":{"fields":{"slug":"/posts/2024//llm/dissecting-llama-32","categorySlug":"/category/llm/"},"frontmatter":{"description":"A shot at understanding Llama3.2","category":"LLM","title":"Dissecting Llama3.2","date":"2024-10-27T20:35:37.121Z","slug":"/llm/dissecting-llama-32"}}}]}},"pageContext":{"group":"LLM","limit":4,"offset":0,"pagination":{"currentPage":0,"prevPagePath":"/category/llm","nextPagePath":"/category/llm/page/1","hasNextPage":true,"hasPrevPage":false}}},"staticQueryHashes":["251939775","288581551","401334301","63107425"]}