{"componentChunkName":"component---src-templates-post-template-post-template-tsx","path":"/hadoop/hdfs","result":{"data":{"markdownRemark":{"id":"3127ca44-0b95-5a4c-b49d-bb152958cdbd","html":"<h1 id=\"tldr\" style=\"position:relative;\"><a href=\"#tldr\" aria-label=\"tldr permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>TL;DR</h1>\n<h3 id=\"hdfs는-대규모의-데이터를-분산-저장하여-read-효율을-향상시킨다\" style=\"position:relative;\"><a href=\"#hdfs%EB%8A%94-%EB%8C%80%EA%B7%9C%EB%AA%A8%EC%9D%98-%EB%8D%B0%EC%9D%B4%ED%84%B0%EB%A5%BC-%EB%B6%84%EC%82%B0-%EC%A0%80%EC%9E%A5%ED%95%98%EC%97%AC-read-%ED%9A%A8%EC%9C%A8%EC%9D%84-%ED%96%A5%EC%83%81%EC%8B%9C%ED%82%A8%EB%8B%A4\" aria-label=\"hdfs는 대규모의 데이터를 분산 저장하여 read 효율을 향상시킨다 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>HDFS는 대규모의 데이터를 분산 저장하여 read 효율을 향상시킨다</h3>\n<p>글또에 참여하면서 자연스럽게 평소에 관심있던 데이터 엔지니어링 분야의 스터디에 참여하게 되었다. 데이터 분야에서 근무중인 다른 엔지니어 분들을 통해 많이 배우고 있다. 매 주 한명씩 발표를 하는데, 발표를 담당했던 HDFS에 대해 이야기 해보려고 한다.</p>\n<p>가장 큰 특징은 데이터를 <code class=\"language-text\">클러스터</code> 전반에 나누어서 저장하고. 데이터에 빠르고 안정적으로 접근할 수 있다는 것이다. 이렇게 나누어진 데이터를 <code class=\"language-text\">block</code>이라고 칭하고, 한 <code class=\"language-text\">block</code>은 128MB이다. 또한 여러개의 컴퓨터에서 동시에 특정 데이터에 접근할 수 있다.</p>\n<p><img src=\"https://i.imgur.com/m8rGbKK.png\" alt=\"HDFS 저장방식\"></p>\n<p>HDFS의 기본구조는 아래 그림과 같이 1개의 Name Node와 여러개의 Data Node로 구성되어 있다.</p>\n<p><img src=\"https://i.imgur.com/8o8HG7B.png\" alt=\"HDFS Architecture\"></p>\n<p><code class=\"language-text\">data node</code>는 실제 <code class=\"language-text\">block</code>들이 저장되는 공간이고, <code class=\"language-text\">name node</code>는 분산되어 저장된 각 <code class=\"language-text\">block</code>들이 어떤 <code class=\"language-text\">data node</code>에 저장되어있는지 기억하는 역할을 한다. HDFS는 데이터가 들어오면 원본만 저장하는 것이아니라, 복사본도 저장을 하는데, <code class=\"language-text\">name node</code>는 그 복사본들의 위치까지 저장한다. 또한 언제 데이터의 edit log도 <code class=\"language-text\">name node</code>에 저장된다.</p>\n<p>따라서 <code class=\"language-text\">client node</code>가 <code class=\"language-text\">HDFS</code>에서 파일을 읽기 위해서는 <code class=\"language-text\">block</code>의 모든 정보를 가지고 있는 <code class=\"language-text\">name node</code>에 먼저 접근한다. <code class=\"language-text\">name node</code>로부터 내가 접근하고자 하는 <code class=\"language-text\">block</code>이 어떤 <code class=\"language-text\">data node</code>에 있는지 확인하고, 해당 <code class=\"language-text\">data node</code>에 접근해서 원하는 <code class=\"language-text\">block</code>을 읽어낸다.</p>\n<p><img src=\"https://i.imgur.com/dXbyswZ.png\" alt=\"reading a file from HDFS\"></p>\n<p><code class=\"language-text\">HDFS</code>에 파일을 쓸 때도 역시 <code class=\"language-text\">name node</code>에 먼저 접근한다. <code class=\"language-text\">name node</code>는 <code class=\"language-text\">client node</code>가 작성하고자 하는 데이터의 Entry를 특정 <code class=\"language-text\">data node</code>에 생성하고, 해당 정보를 <code class=\"language-text\">client node</code>에 전달한다. <code class=\"language-text\">client node</code>는 <code class=\"language-text\">name node</code>로 부터 전달받은 <code class=\"language-text\">data node</code>에 write를 시작하고, 해당 block은 data node로 분산되어 저장된다. block의 위치에 관한 정보와 edit log는 <code class=\"language-text\">name node</code>에 저장된다.</p>\n<p><code class=\"language-text\">name node</code>가 하나인 이유는, <code class=\"language-text\">name node</code>가 여러개인 경우에 문제가 발생할 수 있기 때문이다. 만일 여러 <code class=\"language-text\">client node</code>들이 동시에 다양한 <code class=\"language-text\">name node</code>들에게 <code class=\"language-text\">block</code>의 정보를 요청하는 경우, 각 <code class=\"language-text\">client</code>들이 같은 <code class=\"language-text\">block</code>에 접근한다 하더라도 다른 정보를 받아올 수 있다.</p>\n<p>그렇다면 모든 정보를 가지고 있는 <code class=\"language-text\">name node</code>가 고장난다면 어떻게 해야할까? <code class=\"language-text\">HDFS</code>는 <code class=\"language-text\">name node</code>가 고장날 것을 대비해 이런저런 장치들이 있다.</p>\n<ol>\n<li>meta data backup\n<ul>\n<li>local disk나 file system에 name node가 가지고 있는 Edit log를 저장한다.</li>\n<li>name node가 죽게되면, 해당 disk에서 edit log를 불러온다.</li>\n<li>디스크에 접근하는 것은 오래걸리기 때문에 정보를 조금 유실할 수는 있지만, 완전히 잃어버리는 것보다는 낫기 때문이 에런 방식을 사용한다</li>\n</ul>\n</li>\n</ol>\n<p>여기저 저장하는 메타데이터에 대해 조금 더 알아보자면, hadoop은 원래 디스크 말고 메모리에서 파일명, 디렉토리, 블록크기, 소유자, 파일속성 등 모든 메타데이터를 관리한다. 이 메타데이터는 <code class=\"language-text\">fsimage</code>와 <code class=\"language-text\">edits</code>로 나누어지는데, <code class=\"language-text\">fsimage</code>가 파일명, 디렉토리, 블록크기, 소유자, 파일속성과 같이 메모리 상에서 관리되는 메타데이터 내의 파일 이미지이다. socket의 health check와 유사한 <code class=\"language-text\">check point</code>라는 시점에 name node의 로컬 파일시트템에 생성되고, data node 블록 정보는 포함하지 않는다. <code class=\"language-text\">edits</code>는 로컬 파일 시스템에 생성되는 <code class=\"language-text\">edit log</code>이다.</p>\n<ol start=\"2\">\n<li>\n<p>secondary name node</p>\n<ul>\n<li>완전히 동일한 name node는 아니고 name node가 가지고있는 <code class=\"language-text\">edit log</code>의 copy를 저장한다</li>\n<li>name node가 죽으면 바로 대체할 hot standby는 아니지만, name node가 하나 더 있는 방식이기 때문에 meta data를 backup하는 첫번째 방식보다는 복구가 빠르다는 이점이 있다.</li>\n<li>secondary name node는 기존의 name node와는 다른 클러스터에서 돌아가고, meta data에서 설명한 <code class=\"language-text\">fsimage</code>와 <code class=\"language-text\">edits</code>를 주기적으로 name node에서 받아와서 저장한다.</li>\n</ul>\n</li>\n</ol>\n<p><img src=\"https://i.imgur.com/2tH3Fbj.png\" alt=\"secondary name node\"></p>\n<ol start=\"3\">\n<li>High Availability\n<ul>\n<li>이 단어는 여기저기서 자주 사용된다. hot standby라고 보면 된다</li>\n<li>동시에 두개를 켜놓고 잘 돌던게 죽으면 바로 대체한다</li>\n<li>hadoop 생태계의 다른 프로그램(?)인 <code class=\"language-text\">Zookeeper</code>가 어떤 name node가 메인이고, 어떤 name node가 hot standby인지를 파악한다.</li>\n</ul>\n</li>\n</ol>\n<p><img src=\"https://i.imgur.com/nsul5YQ.png\" alt=\"High Availability\"></p>\n<p>앞으로 조금씩 hadoop에 관한 포스팅을 해보도록 하겠다. 회사 인프라팀에서 쿠버네티스를 구축하는 중인데, 요즘 하둡 스터디 한다고 하니까 긍정적인 반응을 보이셨다. 공부 잘 해서 회사에서도 적용할 수 있었으면 좋겠다.</p>\n<p>참고자료</p>\n<ul>\n<li><a href=\"https://www.udemy.com/course/best-hadoop/learn/lecture/28318946?start=30#overview\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">udemy 강의</a></li>\n</ul>","fields":{"slug":"/posts/2022//hadoop/hdfs","tagSlugs":["/tag/hadoop/"]},"frontmatter":{"date":"2022-06-20T22:53:37.121Z","description":"Hadoop에서 HDFS가 하는 역할","tags":["Hadoop"],"title":"Hadoop - HDFS","socialImage":null}}},"pageContext":{"slug":"/posts/2022//hadoop/hdfs"}},"staticQueryHashes":["251939775","288581551","401334301"]}