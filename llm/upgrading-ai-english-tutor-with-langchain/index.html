<!DOCTYPE html><html lang="en"><head><meta charSet="utf-8"/><meta http-equiv="x-ua-compatible" content="ie=edge"/><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"/><meta name="generator" content="Gatsby 4.25.8"/><meta name="description" content="이제 직접 대화 기록을 메모리에서 관리하지 않아도 된다" data-gatsby-head="true"/><meta name="twitter:card" content="summary_large_image" data-gatsby-head="true"/><meta name="twitter:title" content="Langchain을 활용한 인공지능 영어과외 업그레이드 - Blog by Jason Kang" data-gatsby-head="true"/><meta name="twitter:description" content="이제 직접 대화 기록을 메모리에서 관리하지 않아도 된다" data-gatsby-head="true"/><meta name="og:title" content="Langchain을 활용한 인공지능 영어과외 업그레이드 - Blog by Jason Kang" data-gatsby-head="true"/><meta name="og:type" content="website" data-gatsby-head="true"/><meta name="og:description" content="이제 직접 대화 기록을 메모리에서 관리하지 않아도 된다" data-gatsby-head="true"/><meta name="theme-color" content="hsl(31, 92%, 62%)"/><style data-href="/styles.462ccd878fdc76b93a3f.css" data-identity="gatsby-global-css">:after,:before,:root{--color-white:#fff;--color-primary:#5c92ff;--color-secondary:#f7a145;--color-prism-background:#eaeaeb;--color-typographic-base-font:#242933;--color-typographic-link-p-font:#5c92ff;--color-typographic-link-s-font:#f7a145;--color-page-border:#eaeaeb;--color-page-background:#fff;--color-sidebar-border:#eaeaeb;--color-sidebar-border-fade:#fff;--color-contacts-border:#eaeaeb;--color-button-border:#eaeaeb;--color-button-color:#242933;--color-theme-switcher:#3f485a;--color-theme-switcher-hover:#5c92ff}.dark :after,.dark :before,:root.dark{--color-white:#fff;--color-primary:#5c92ff;--color-secondary:#f7a145;--color-prism-background:#191d24;--color-typographic-base-font:#fff;--color-typographic-link-p-font:#5c92ff;--color-typographic-link-s-font:#f7a145;--color-page-border:#3f485a;--color-page-background:#242933;--color-sidebar-border:#3f485a;--color-sidebar-border-fade:#242933;--color-contacts-border:#3f485a;--color-button-border:#3f485a;--color-button-color:#fff;--color-theme-switcher:#eaeaeb;--color-theme-switcher-hover:#5c92ff}html{font-size:100}body{-webkit-font-smoothing:antialiased;-moz-osx-font-smoothing:grayscale;-ms-text-size-adjust:100%;-webkit-text-size-adjust:100%;background:var(--color-page-background);color:var(--color-typographic-base-font);font-size:16px;line-height:1.625;margin:0 0 0 calc(100vw - 100%);text-rendering:optimizelegibility}body,h1,h2,h3,h4,h5,h6{font-family:-apple-system,BlinkMacSystemFont,Segoe UI,Roboto,Oxygen-Sans,Ubuntu,Cantarell,Helvetica Neue,sans-serif}h1,h2,h3,h4,h5,h6{font-weight:600}h1{font-size:40px;line-height:52px;margin-bottom:26px;margin-top:104px}h2{font-size:27px;line-height:39px}h2,h3{margin-bottom:13px;margin-top:52px}h3{font-size:22px;line-height:26px}h4{font-size:19.2px;margin-top:39px}h4,h5{line-height:26px;margin-bottom:13px}h5,h6{font-size:16px;margin-top:65px}h6{line-height:26px;margin-bottom:13px}img{max-width:100%}hr,img{border:0;display:block}hr{background-image:linear-gradient(180deg,transparent 1px,transparent 11px,#242933 0,#242933 15px,transparent 0,transparent 26px);background-size:100% 26px;color:var(--color-typographic-base-font);height:26px;margin:52px auto;width:100px}a{color:var(--color-typographic-link-p-font);text-decoration:none}a:active,a:focus,a:hover{color:var(--color-typographic-link-s-font)}b,strong{font-weight:600}ul{list-style:square;margin-bottom:26px}ul li{margin-bottom:10px;padding:0 5px}p{line-height:26px;margin-bottom:26px}blockquote{font-style:italic;padding:0;text-align:center}figure{display:block;height:auto;width:100%}figcaption{color:var(--color-typographic-base-font);font-size:14px;font-style:italic;line-height:19.5px;margin-bottom:0;margin-top:6.5px;text-align:center}@media screen and (min-width:685px){figure.float-left,figure.float-right{max-width:310px;padding:0 26px}.float-right{float:right}.float-left{float:left}}code[class*=language-],pre[class*=language-]{word-wrap:normal;color:#657b83;font-family:Consolas,Monaco,Andale Mono,Ubuntu Mono,monospace;font-size:1em;-webkit-hyphens:none;hyphens:none;line-height:1.5;tab-size:4;text-align:left;white-space:pre;word-break:normal;word-spacing:normal}pre[class*=language-]{border-radius:.3em;margin:.5em 0;overflow:auto;padding:1em}:not(pre)>code[class*=language-],pre[class*=language-]{background-color:var(--color-prism-background)}:not(pre)>code[class*=language-]{border-radius:.3em;padding:.1em}code[class*=language-] ::selection,code[class*=language-]::selection,pre[class*=language-] ::selection,pre[class*=language-]::selection{background:#073642}.token.cdata,.token.comment,.token.doctype,.token.prolog{color:#93a1a1}.token.punctuation{color:#586e75}.namespace{opacity:.7}.token.boolean,.token.constant,.token.deleted,.token.number,.token.property,.token.symbol,.token.tag{color:#268bd2}.token.attr-name,.token.builtin,.token.char,.token.inserted,.token.selector,.token.string,.token.url{color:#2aa198}.token.entity{background:#eee8d5;color:#657b83;cursor:help}.token.atrule,.token.attr-value,.token.keyword{color:#859900}.token.class-name,.token.function{color:#b58900}.token.important,.token.regex,.token.variable{color:#cb4b16}.token.bold,.token.important{font-weight:700}.token.italic{font-style:italic}.Feed-module--feed--a6204 .Feed-module--item--c7a63{margin-bottom:32.5px}.Feed-module--feed--a6204 .Feed-module--item--c7a63:last-child{margin-bottom:13px}.Feed-module--feed--a6204 .Feed-module--item--c7a63 .Feed-module--title--f252f{font-size:27px;line-height:39px;margin-bottom:13px;margin-top:0}.Feed-module--feed--a6204 .Feed-module--item--c7a63 .Feed-module--title--f252f .Feed-module--link--6123b{color:var(--color-typographic-base-font)}.Feed-module--feed--a6204 .Feed-module--item--c7a63 .Feed-module--title--f252f .Feed-module--link--6123b:focus,.Feed-module--feed--a6204 .Feed-module--item--c7a63 .Feed-module--title--f252f .Feed-module--link--6123b:hover{border-bottom:1px solid #242933;color:var(--color-typographic-base-font)}.Feed-module--feed--a6204 .Feed-module--item--c7a63 .Feed-module--description--57348{font-size:16px;line-height:26px;margin-bottom:19.5px}.Feed-module--feed--a6204 .Feed-module--item--c7a63 .Feed-module--meta--250c2 .Feed-module--time--72864{color:var(--color-typographic-base-font);font-size:14px;font-weight:600;text-transform:uppercase}.Feed-module--feed--a6204 .Feed-module--item--c7a63 .Feed-module--meta--250c2 .Feed-module--divider--81a18{margin:0 13px}.Feed-module--feed--a6204 .Feed-module--item--c7a63 .Feed-module--meta--250c2 .Feed-module--category--59f58 .Feed-module--link--6123b{color:var(--color-secondary);font-size:14px;font-weight:600;text-transform:uppercase}.Feed-module--feed--a6204 .Feed-module--item--c7a63 .Feed-module--meta--250c2 .Feed-module--category--59f58 .Feed-module--link--6123b:focus,.Feed-module--feed--a6204 .Feed-module--item--c7a63 .Feed-module--meta--250c2 .Feed-module--category--59f58 .Feed-module--link--6123b:hover{color:#5c92ff}.Feed-module--feed--a6204 .Feed-module--item--c7a63 .Feed-module--more--51a4e{color:var(--color-primary);font-size:16px}.Feed-module--feed--a6204 .Feed-module--item--c7a63 .Feed-module--more--51a4e:focus,.Feed-module--feed--a6204 .Feed-module--item--c7a63 .Feed-module--more--51a4e:hover{border-bottom:1px solid #5c92ff;color:var(--color-primary)}.Layout-module--layout--2c933{margin-left:auto;margin-right:auto;max-width:1070px}.Layout-module--layout--2c933:before{content:"";display:table}.Layout-module--layout--2c933:after{clear:both;content:"";display:table}.Page-module--page--24e03{margin-bottom:52px}.Page-module--page--24e03 .Page-module--inner--4b31d{padding:26px 19.5px 0}.Page-module--page--24e03 .Page-module--title--90338{font-size:40px;font-weight:600;line-height:52px;margin-bottom:37.7px;margin-top:0}.Page-module--page--24e03 .Page-module--body--561c4{font-size:16px;line-height:26px;margin:0 0 26px}@media screen and (min-width:685px){.Page-module--page--24e03{width:calc(58.275% - 12.5px)}.Page-module--page--24e03:nth-child(1n){clear:none;float:left;margin-right:30px}.Page-module--page--24e03:last-child{margin-right:0}.Page-module--page--24e03:nth-child(12n){float:right;margin-right:0}.Page-module--page--24e03:nth-child(12n+1){clear:both}.Page-module--page--24e03 .Page-module--inner--4b31d{padding:32.5px 19.5px 0}}@media screen and (min-width:960px){.Page-module--page--24e03{width:calc(66.6% - 10px)}.Page-module--page--24e03:nth-child(1n){clear:none;float:left;margin-right:30px}.Page-module--page--24e03:last-child{margin-right:0}.Page-module--page--24e03:nth-child(3n){float:right;margin-right:0}.Page-module--page--24e03:nth-child(3n+1){clear:both}.Page-module--page--24e03 .Page-module--inner--4b31d{padding:39px 26px 0}}.Pagination-module--pagination--d61cb{display:flex;margin-top:52px}.Pagination-module--pagination--d61cb .Pagination-module--previous--4a76b{text-align:left;width:50%}.Pagination-module--pagination--d61cb .Pagination-module--previous--4a76b .Pagination-module--previousLink--5590d{color:var(--color-secondary);font-size:26px;font-weight:700}.Pagination-module--pagination--d61cb .Pagination-module--previous--4a76b .Pagination-module--previousLink--5590d:focus,.Pagination-module--pagination--d61cb .Pagination-module--previous--4a76b .Pagination-module--previousLink--5590d:hover{color:var(--color-primary)}.Pagination-module--pagination--d61cb .Pagination-module--previous--4a76b .Pagination-module--previousLink--5590d.Pagination-module--disable--7e105{color:#3f485a;pointer-events:none}.Pagination-module--pagination--d61cb .Pagination-module--next--1cab8{text-align:right;width:50%}.Pagination-module--pagination--d61cb .Pagination-module--next--1cab8 .Pagination-module--nextLink--532ff{color:var(--color-secondary);font-size:26px;font-weight:700}.Pagination-module--pagination--d61cb .Pagination-module--next--1cab8 .Pagination-module--nextLink--532ff:focus,.Pagination-module--pagination--d61cb .Pagination-module--next--1cab8 .Pagination-module--nextLink--532ff:hover{color:var(--color-primary)}.Pagination-module--pagination--d61cb .Pagination-module--next--1cab8 .Pagination-module--nextLink--532ff.Pagination-module--disable--7e105{color:#3f485a;pointer-events:none}.Button-module--button--b1113{border:1px solid var(--color-button-border);border-radius:20px;color:var(--color-button-color);display:inline-block;font-size:16px;font-weight:400;height:40px;line-height:40px;margin-left:auto;margin-right:auto;padding:0 26px;text-align:center;text-decoration:none}.Button-module--button--b1113:focus,.Button-module--button--b1113:hover{color:#5c92ff}.ThemeSwitcher-module--themeSwitcher--8a77f{--color:var(--color-theme-switcher)}.ThemeSwitcher-module--themeSwitcher--8a77f .ThemeSwitcher-module--button--7cb7b{align-items:center;background:transparent;border:0;cursor:pointer;display:flex;justify-content:center;outline:0}.ThemeSwitcher-module--themeSwitcher--8a77f .ThemeSwitcher-module--button--7cb7b svg{stroke:var(--color);pointer-events:none;transition:stroke .4s}.ThemeSwitcher-module--themeSwitcher--8a77f .ThemeSwitcher-module--button--7cb7b:hover{--color:var(--color-theme-switcher-hover)}.ThemeSwitcher-module--themeSwitcher--8a77f .ThemeSwitcher-module--moon--10537{stroke-dasharray:0 1px;opacity:0;transition:stroke-dasharray .2s ease-in,opacity .4s ease-in}.ThemeSwitcher-module--themeSwitcher--8a77f .ThemeSwitcher-module--sun--2163a{stroke-dasharray:1px 1px;opacity:1;transition:stroke-dasharray .2s ease-in,opacity .4s ease-in}.ThemeSwitcher-module--themeSwitcher--8a77f.ThemeSwitcher-module--dark--6db0c .ThemeSwitcher-module--moon--10537{stroke-dasharray:1px 1px;opacity:1}.ThemeSwitcher-module--themeSwitcher--8a77f.ThemeSwitcher-module--dark--6db0c .ThemeSwitcher-module--sun--2163a{stroke-dasharray:0 1px;opacity:0}.Author-module--author--cbd31 .Author-module--photo--9787b{background-clip:padding-box;border-radius:50%;display:inline-block;height:75px;margin-bottom:0;width:75px}.Author-module--author--cbd31 .Author-module--photo--9787b img{border-radius:50%}.Author-module--author--cbd31 .Author-module--title--cf7e5{font-size:18px;font-weight:600;line-height:29.25px;margin:0}.Author-module--author--cbd31 .Author-module--title--cf7e5 .Author-module--link--09c17,.Author-module--author--cbd31 .Author-module--title--cf7e5 .Author-module--link--09c17:focus,.Author-module--author--cbd31 .Author-module--title--cf7e5 .Author-module--link--09c17:hover{color:var(--color-typographic-base-font)}.Author-module--author--cbd31 .Author-module--subtitle--86ec5{color:#7f8ba4;line-height:26px;margin-bottom:26px}.Author-module--author--cbd31 .Author-module--titleContainer--4f576{align-items:center;display:flex;justify-content:space-between;margin:13px 0}.Icon-module--icon--1d7da{fill:currentcolor;-webkit-font-smoothing:antialiased;-moz-osx-font-smoothing:grayscale;speak:none;stroke:currentcolor;stroke-width:0;display:inline-block;font-style:normal;font-variant:normal;font-weight:400;height:1em;line-height:1em;text-align:center;text-transform:none;width:1em}.Contacts-module--contacts--09178{margin-bottom:26px}.Contacts-module--contacts--09178 .Contacts-module--list--9670b{display:flex;flex-flow:row wrap;flex-grow:0;flex-shrink:0;list-style:none;margin:13px 0;max-width:165px;padding:0}.Contacts-module--contacts--09178 .Contacts-module--list--9670b .Contacts-module--item--f9cb0{align-content:center;align-items:center;border:1px solid var(--color-contacts-border);border-radius:50%;display:flex;height:40px;justify-content:center;line-height:40px;margin:6.5px;padding:0;text-align:center;width:40px}.Contacts-module--contacts--09178 .Contacts-module--list--9670b .Contacts-module--item--f9cb0:nth-child(3n+1){margin-left:0}.Contacts-module--contacts--09178 .Contacts-module--list--9670b .Contacts-module--item--f9cb0 .Contacts-module--link--de1e0{border:0;color:var(--color-typographic-base-font);cursor:pointer;display:flex}.Contacts-module--contacts--09178 .Contacts-module--list--9670b .Contacts-module--item--f9cb0 .Contacts-module--link--de1e0:focus,.Contacts-module--contacts--09178 .Contacts-module--list--9670b .Contacts-module--item--f9cb0 .Contacts-module--link--de1e0:hover{color:var(--color-typographic-link-p-font)}.Copyright-module--copyright--2c602{color:#7f8ba4;font-size:14px}.Menu-module--menu--113a9{margin-bottom:26px}.Menu-module--menu--113a9 .Menu-module--list--e1ae3{list-style:none;margin:0;padding:0}.Menu-module--menu--113a9 .Menu-module--list--e1ae3 .Menu-module--item--8b679{margin:13px 0;padding:0}.Menu-module--menu--113a9 .Menu-module--list--e1ae3 .Menu-module--item--8b679 .Menu-module--link--a6f02{border:0;color:var(--color-typographic-base-font);font-size:16px;font-weight:400}.Menu-module--menu--113a9 .Menu-module--list--e1ae3 .Menu-module--item--8b679 .Menu-module--link--a6f02:focus,.Menu-module--menu--113a9 .Menu-module--list--e1ae3 .Menu-module--item--8b679 .Menu-module--link--a6f02:hover{border-bottom:1px solid #5c92ff;color:#5c92ff}.Menu-module--menu--113a9 .Menu-module--list--e1ae3 .Menu-module--item--8b679 .Menu-module--link--a6f02.Menu-module--active--6cb74{border-bottom:1px solid var(--color-typographic-base-font);color:var(--color-typographic-base-font)}.Sidebar-module--sidebar--1bfa1{width:100%}.Sidebar-module--sidebar--1bfa1 .Sidebar-module--inner--344d0{padding:26px 19.5px 0;position:relative}.Sidebar-module--sidebar--1bfa1 .Sidebar-module--inner--344d0:after{background:var(--color-sidebar-border);background:linear-gradient(to bottom,var(--color-sidebar-border) 0,var(--color-sidebar-border) 48%,var(--color-sidebar-border-fade) 100%)}@media screen and (min-width:685px){.Sidebar-module--sidebar--1bfa1{width:calc(41.625% - 17.5px)}.Sidebar-module--sidebar--1bfa1:nth-child(1n){clear:none;float:left;margin-right:30px}.Sidebar-module--sidebar--1bfa1:last-child{margin-right:0}.Sidebar-module--sidebar--1bfa1:nth-child(12n){float:right;margin-right:0}.Sidebar-module--sidebar--1bfa1:nth-child(12n+1){clear:both}.Sidebar-module--sidebar--1bfa1 .Sidebar-module--inner--344d0{padding:32.5px 19.5px 0}.Sidebar-module--sidebar--1bfa1 .Sidebar-module--inner--344d0:after{bottom:0;content:"";height:540px;position:absolute;right:-10px;top:30px;width:1px}}@media screen and (min-width:960px){.Sidebar-module--sidebar--1bfa1{width:calc(33.3% - 20px)}.Sidebar-module--sidebar--1bfa1:nth-child(1n){clear:none;float:left;margin-right:30px}.Sidebar-module--sidebar--1bfa1:last-child{margin-right:0}.Sidebar-module--sidebar--1bfa1:nth-child(3n){float:right;margin-right:0}.Sidebar-module--sidebar--1bfa1:nth-child(3n+1){clear:both}.Sidebar-module--sidebar--1bfa1 .Sidebar-module--inner--344d0{padding:39px}}.Author-module--author--1c58d{border-top:1px solid var(--color-page-border);line-height:26px;margin-bottom:52px;margin-top:26px;max-width:640px;padding-top:26px}.Author-module--author--1c58d .Author-module--bio--08950 .Author-module--twitter--90647{display:block;text-decoration:underline}.Author-module--author--1c58d .Author-module--bio--08950 .Author-module--twitter--90647:focus,.Author-module--author--1c58d .Author-module--bio--08950 .Author-module--twitter--90647:hover{color:var(--color-typographic-link-s-font)}@media screen and (min-width:685px){.Author-module--author--1c58d{margin-left:auto;margin-right:auto}}.Content-module--content--80d58{margin:0 auto;max-width:945px;padding:0 13px}.Content-module--content--80d58 .Content-module--title--09504{font-size:32px;font-weight:600;line-height:42.9px;margin:26px auto 0;max-width:640px;text-align:center}.Content-module--content--80d58 .Content-module--body--726c2 figure{margin-bottom:26px}.Content-module--content--80d58 .Content-module--body--726c2 figure blockquote{font-style:italic;margin-top:0;padding:26px 0;text-align:center}.Content-module--content--80d58 .Content-module--body--726c2 figure blockquote p{font-size:26.9072px;line-height:39px;margin-bottom:26px;margin-top:0;max-width:640px}.Content-module--content--80d58 .Content-module--body--726c2 a{text-decoration:underline}.Content-module--content--80d58 .Content-module--body--726c2 *{margin-left:auto;margin-right:auto;max-width:640px}.Content-module--content--80d58 .Content-module--body--726c2 h2>a{visibility:hidden}.Content-module--content--80d58 .Content-module--body--726c2 h2>a>svg{fill:var(--color-typographic-base-font)}.Content-module--content--80d58 .Content-module--body--726c2 img{max-width:100%}@media screen and (min-width:960px){.Content-module--content--80d58{padding:0}.Content-module--content--80d58 .Content-module--title--09504{font-size:48px;line-height:58.5px;margin-bottom:39px;margin-top:58.5px}.Content-module--content--80d58 .Content-module--body--726c2,.Content-module--content--80d58 .Content-module--body--726c2 p{font-size:18px;line-height:29.25px;margin-bottom:29.25px}.Content-module--content--80d58 .Content-module--body--726c2 h2>a{padding-right:13px;visibility:unset}}.Meta-module--meta--dae0a .Meta-module--date--4d30d{font-style:italic}.Tags-module--tags--18589{margin-bottom:13px}.Tags-module--tags--18589 .Tags-module--list--82ae6{list-style:none;padding:0}.Tags-module--tags--18589 .Tags-module--list--82ae6 .Tags-module--item--52015{display:inline-block;margin:6.5px 0}@media screen and (min-width:685px){.Tags-module--tags--18589 .Tags-module--list--82ae6 .Tags-module--item--52015:first-child{margin-left:0;padding-left:0}}.Post-module--post--3a994 .Post-module--content--3c6e5{margin:0 auto}.Post-module--post--3a994 .Post-module--comments--d3b99,.Post-module--post--3a994 .Post-module--footer--f8705{margin:0 auto;max-width:640px;padding:0 13px}.Post-module--post--3a994 .Post-module--buttons--2972d{align-items:center;display:flex;justify-content:center;margin:26px 0 0;text-align:center}.Post-module--post--3a994 .Post-module--buttons--2972d .Post-module--buttonArticles--d793a{margin:0 13px 0 0}@media screen and (min-width:960px){.Post-module--post--3a994 .Post-module--comments--d3b99,.Post-module--post--3a994 .Post-module--footer--f8705{padding:0}.Post-module--post--3a994 .Post-module--buttons--2972d{left:30px;margin:0 13px 0 0;max-width:none;position:fixed;top:30px}}</style><title data-gatsby-head="true">Langchain을 활용한 인공지능 영어과외 업그레이드 - Blog by Jason Kang</title><script async="" src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script><script>            
              (adsbygoogle = window.adsbygoogle || []).push({
                google_ad_client: "ca-pub-2002611361597206",
                enable_page_level_ads: true
              });
          </script><link rel="preconnect" href="https://www.googletagmanager.com"/><link rel="dns-prefetch" href="https://www.googletagmanager.com"/><script async="" src="https://www.googletagmanager.com/gtag/js?id=G-8BHCT1V21F"></script><script>
      
      
      if(true) {
        window.dataLayer = window.dataLayer || [];
        function gtag(){dataLayer.push(arguments);}
        gtag('js', new Date());

        gtag('config', 'G-8BHCT1V21F', {"send_page_view":false});
      }
      </script><link rel="alternate" type="application/rss+xml" title="Blog by Jason Kang" href="/rss.xml"/><style type="text/css">
    .anchor.before {
      position: absolute;
      top: 0;
      left: 0;
      transform: translateX(-100%);
      padding-right: 4px;
    }
    .anchor.after {
      display: inline-block;
      padding-left: 4px;
    }
    h1 .anchor svg,
    h2 .anchor svg,
    h3 .anchor svg,
    h4 .anchor svg,
    h5 .anchor svg,
    h6 .anchor svg {
      visibility: hidden;
    }
    h1:hover .anchor svg,
    h2:hover .anchor svg,
    h3:hover .anchor svg,
    h4:hover .anchor svg,
    h5:hover .anchor svg,
    h6:hover .anchor svg,
    h1 .anchor:focus svg,
    h2 .anchor:focus svg,
    h3 .anchor:focus svg,
    h4 .anchor:focus svg,
    h5 .anchor:focus svg,
    h6 .anchor:focus svg {
      visibility: visible;
    }
  </style><script>
    document.addEventListener("DOMContentLoaded", function(event) {
      var hash = window.decodeURI(location.hash.replace('#', ''))
      if (hash !== '') {
        var element = document.getElementById(hash)
        if (element) {
          var scrollTop = window.pageYOffset || document.documentElement.scrollTop || document.body.scrollTop
          var clientTop = document.documentElement.clientTop || document.body.clientTop || 0
          var offset = element.getBoundingClientRect().top + scrollTop - clientTop
          // Wait for the browser to finish rendering before scrolling.
          setTimeout((function() {
            window.scrollTo(0, offset - 0)
          }), 0)
        }
      }
    })
  </script><link rel="sitemap" type="application/xml" href="/sitemap/sitemap-index.xml"/><link rel="icon" href="/favicon-32x32.png?v=110dbcaf7b73f2d646b07137b9e3af54" type="image/png"/><link rel="manifest" href="/manifest.webmanifest" crossorigin="anonymous"/><link rel="apple-touch-icon" sizes="48x48" href="/icons/icon-48x48.png?v=110dbcaf7b73f2d646b07137b9e3af54"/><link rel="apple-touch-icon" sizes="72x72" href="/icons/icon-72x72.png?v=110dbcaf7b73f2d646b07137b9e3af54"/><link rel="apple-touch-icon" sizes="96x96" href="/icons/icon-96x96.png?v=110dbcaf7b73f2d646b07137b9e3af54"/><link rel="apple-touch-icon" sizes="144x144" href="/icons/icon-144x144.png?v=110dbcaf7b73f2d646b07137b9e3af54"/><link rel="apple-touch-icon" sizes="192x192" href="/icons/icon-192x192.png?v=110dbcaf7b73f2d646b07137b9e3af54"/><link rel="apple-touch-icon" sizes="256x256" href="/icons/icon-256x256.png?v=110dbcaf7b73f2d646b07137b9e3af54"/><link rel="apple-touch-icon" sizes="384x384" href="/icons/icon-384x384.png?v=110dbcaf7b73f2d646b07137b9e3af54"/><link rel="apple-touch-icon" sizes="512x512" href="/icons/icon-512x512.png?v=110dbcaf7b73f2d646b07137b9e3af54"/><style>.gatsby-image-wrapper{position:relative;overflow:hidden}.gatsby-image-wrapper picture.object-fit-polyfill{position:static!important}.gatsby-image-wrapper img{bottom:0;height:100%;left:0;margin:0;max-width:none;padding:0;position:absolute;right:0;top:0;width:100%;object-fit:cover}.gatsby-image-wrapper [data-main-image]{opacity:0;transform:translateZ(0);transition:opacity .25s linear;will-change:opacity}.gatsby-image-wrapper-constrained{display:inline-block;vertical-align:top}</style><noscript><style>.gatsby-image-wrapper noscript [data-main-image]{opacity:1!important}.gatsby-image-wrapper [data-placeholder-image]{opacity:0!important}</style></noscript><script type="module">const e="undefined"!=typeof HTMLImageElement&&"loading"in HTMLImageElement.prototype;e&&document.body.addEventListener("load",(function(e){const t=e.target;if(void 0===t.dataset.mainImage)return;if(void 0===t.dataset.gatsbyImageSsr)return;let a=null,n=t;for(;null===a&&n;)void 0!==n.parentNode.dataset.gatsbyImageWrapper&&(a=n.parentNode),n=n.parentNode;const o=a.querySelector("[data-placeholder-image]"),r=new Image;r.src=t.currentSrc,r.decode().catch((()=>{})).then((()=>{t.style.opacity=1,o&&(o.style.opacity=0,o.style.transition="opacity 500ms linear")}))}),!0);</script></head><body><script>
          void function() {
            var cachedMode;

            try {
              var preferredTheme = JSON.parse(localStorage.getItem('diesel:theme-atom'));

              if (preferredTheme && preferredTheme.mode) {
                cachedMode = preferredTheme.mode;
              }
            } catch (err) { }

            function setTheme(newTheme) {
              document.documentElement.className = newTheme;
            }

            var darkQuery = window.matchMedia('(prefers-color-scheme: dark)');

            setTheme(cachedMode || (darkQuery.matches ? 'dark' : 'light'));
          }()
        </script><div id="___gatsby"><div style="outline:none" tabindex="-1" id="gatsby-focus-wrapper"><div class="Layout-module--layout--2c933"><div class="Post-module--post--3a994"><div class="Post-module--buttons--2972d"><a class="Button-module--button--b1113 Post-module--buttonArticles--d793a" href="/">All Articles</a></div><div class="Post-module--content--3c6e5"><div class="Content-module--content--80d58"><h1 class="Content-module--title--09504">Langchain을 활용한 인공지능 영어과외 업그레이드</h1><div class="Content-module--body--726c2"><p>AI English Tutor의 MVP는 순수하게 OpenAI의 API만 활용해서 개발했다. 다음주에 회사에서 해커톤의 LLM버전인 프롬프톤이라는 행사를 하는데, 이로인해 개발팀이 모여서 <code class="language-text">Langchain을 활용한 어플리케이션 개발</code> 이라는 주제로 스터디를 했다. 스터디를 하면서 보니 Langchain에서 제공하는 <a href="https://python.langchain.com/docs/modules/memory/conversational_customization" target="_blank" rel="nofollow noopener noreferrer">ConversaionChain</a>을 사용하면, 내가 직접 대화기록을 관리하면서 리스트로 넘겨주지 않아도 된다는 것을 깨달았다. 그래서 코드 관리 효율을 개선하고, 귀찮음(?)을 줄이기 위해 Langchain을 활용해서 한 번 업데이트 해보기로 했다.</p>
<p>기존 코드는 파이썬 리스트를 활용해서 대화 기록을 관리한다</p>
<div class="gatsby-highlight" data-language="python"><pre class="language-python"><code class="language-python"><span class="token keyword">import</span> json

history <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span> <span class="token comment"># 대화 내용을 저장하는 메모리</span>

<span class="token keyword">def</span> <span class="token function">talk_to_gpt</span><span class="token punctuation">(</span>user_input<span class="token punctuation">)</span><span class="token punctuation">:</span>
  gpt_response <span class="token operator">=</span> get_gpt_response<span class="token punctuation">(</span>user_input<span class="token punctuation">,</span> history<span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">10</span><span class="token punctuation">:</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
  gpt_response <span class="token operator">=</span> json<span class="token punctuation">.</span>loads<span class="token punctuation">(</span>gpt_response<span class="token punctuation">)</span>
  gpt_response <span class="token operator">=</span> gpt_response<span class="token punctuation">[</span><span class="token string">'response'</span><span class="token punctuation">]</span>
  history<span class="token punctuation">.</span>extend<span class="token punctuation">(</span><span class="token punctuation">[</span>
      <span class="token punctuation">{</span><span class="token string">"role"</span><span class="token punctuation">:</span> <span class="token string">"user"</span><span class="token punctuation">,</span> <span class="token string">"content"</span><span class="token punctuation">:</span> user_input<span class="token punctuation">}</span><span class="token punctuation">,</span> 
      <span class="token punctuation">{</span><span class="token string">"role"</span><span class="token punctuation">:</span> <span class="token string">"assistant"</span><span class="token punctuation">,</span> <span class="token string">"content"</span><span class="token punctuation">:</span> gpt_response<span class="token punctuation">}</span>
  <span class="token punctuation">]</span><span class="token punctuation">)</span></code></pre></div>
<p>gpt에서 json 형태로 응답을 주면, 해당 json을 parsing해서 리스트에 넣는 방식이다. 이제 Langchain을 활용하면 어떻게 이 코드가 간단해지는지 확인해보자.</p>
<div class="gatsby-highlight" data-language="python"><pre class="language-python"><code class="language-python"><span class="token comment"># Now we can override it and set it to "AI Assistant"</span>
<span class="token keyword">from</span> langchain<span class="token punctuation">.</span>prompts<span class="token punctuation">.</span>prompt <span class="token keyword">import</span> PromptTemplate

template <span class="token operator">=</span> <span class="token triple-quoted-string string">"""The following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.

Current conversation:
{history}
Human: {input}
AI Assistant:"""</span>
PROMPT <span class="token operator">=</span> PromptTemplate<span class="token punctuation">(</span>input_variables<span class="token operator">=</span><span class="token punctuation">[</span><span class="token string">"history"</span><span class="token punctuation">,</span> <span class="token string">"input"</span><span class="token punctuation">]</span><span class="token punctuation">,</span> template<span class="token operator">=</span>template<span class="token punctuation">)</span>
conversation <span class="token operator">=</span> ConversationChain<span class="token punctuation">(</span>
    prompt<span class="token operator">=</span>PROMPT<span class="token punctuation">,</span>
    llm<span class="token operator">=</span>llm<span class="token punctuation">,</span>
    verbose<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span>
    memory<span class="token operator">=</span>ConversationBufferMemory<span class="token punctuation">(</span>ai_prefix<span class="token operator">=</span><span class="token string">"AI Assistant"</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
<span class="token punctuation">)</span>

conversation<span class="token punctuation">.</span>predict<span class="token punctuation">(</span><span class="token builtin">input</span><span class="token operator">=</span><span class="token string">"Hi there!"</span><span class="token punctuation">)</span></code></pre></div>
<p>공식문서에서 제시하는 예제코드를 보면, 사용자가 전달하는 내용은 프롬프트에 <code class="language-text">input</code>으로 들어가고, 기존의 대화 내용은 프롬프트에 <code class="language-text">history</code>로 들어가는 것을 볼 수 있다. 파이썬 스트링에서 f-string 문법에서 f만 제외하고 중괄호를 넣으면, 랭체인은 해당 값이 <code class="language-text">input_variables</code>에 포함되었는지 확인하고, 함수 파라미터로 받아와서 넘겨주는 방식이다. 공식문서에서 제공하는 프롬프트는, 대화 내용을 기억하고 대화를 잘나누라고 되어있는데. 나는 목적이 영어과외이니 기본 system prompt를 수정해보았다.</p>
<div class="gatsby-highlight" data-language="python"><pre class="language-python"><code class="language-python">prompt_template <span class="token operator">=</span> <span class="token triple-quoted-string string">"""
The following is a friendly conversation between a human and an AI.
The AI a top-tier English tutor with years of experience.
The AI is talking to a student who wants to practice speaking English. 
The AI is to help the student practice speaking English by having a conversation. 

The AI should feel free to correct the student's grammar and pronunciation and/or suggest different words or phrases to use whenever the AI feels needed.
And when the AI corrects the student, the AI must start the sentence with "it is better to put it this way"
But even when you correct the student, try to make a conversation first, and then correct the student

Current conversation:
{history}
Human: {input}
AI Tutor:"""</span></code></pre></div>
<p>트랜스포머의 작동 원리를 생각하면 프롬프트를 최대한 자세히 적어주어야 context를 잘 파악해서 가장 좋은 결과를 낼 것 같은데, 이런저런 실험들을 해보니 오히려 간결하게 instruction을 전달하는 것이 LLM이 답변을 생성하는데 더 유리한 것 같다. 일단 위와 같이 프롬프트를 작성하고, <code class="language-text">ConversationChain</code>을 활용해서 답변을 제작하도록 기존 코드를 수정했다.</p>
<div class="gatsby-highlight" data-language="python"><pre class="language-python"><code class="language-python"><span class="token comment"># Import necessary classes from the langchain and langchain_openai libraries</span>
<span class="token keyword">from</span> langchain<span class="token punctuation">.</span>chains <span class="token keyword">import</span> ConversationChain
<span class="token keyword">from</span> langchain<span class="token punctuation">.</span>memory <span class="token keyword">import</span> ConversationBufferMemory
<span class="token keyword">from</span> langchain<span class="token punctuation">.</span>prompts<span class="token punctuation">.</span>prompt <span class="token keyword">import</span> PromptTemplate
<span class="token keyword">from</span> langchain_openai <span class="token keyword">import</span> OpenAI

<span class="token comment"># Initialize the OpenAI model with a specified temperature.</span>
<span class="token comment"># Temperature set to 0 for deterministic, consistent responses.</span>
llm <span class="token operator">=</span> OpenAI<span class="token punctuation">(</span>
    temperature<span class="token operator">=</span><span class="token number">0</span>
<span class="token punctuation">)</span>

<span class="token comment"># Create a conversation buffer memory to keep track of the conversation.</span>
<span class="token comment"># This includes prefixes to distinguish between the AI tutor and the human user.</span>
memory <span class="token operator">=</span> ConversationBufferMemory<span class="token punctuation">(</span>
    ai_prefix<span class="token operator">=</span><span class="token string">"AI Tutor:"</span><span class="token punctuation">,</span>
    human_prefix<span class="token operator">=</span><span class="token string">"Human:"</span><span class="token punctuation">,</span>
<span class="token punctuation">)</span>

<span class="token comment"># Function to get and configure the conversation chain</span>
<span class="token keyword">def</span> <span class="token function">get_chain</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token comment"># Define a template for the conversation prompt.</span>
    <span class="token comment"># This template sets the context for the conversation and instructions for the AI.</span>
    <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span>
    <span class="token comment"># Create a PromptTemplate object with the defined prompt template.</span>
    <span class="token comment"># This template includes variables for the conversation history and the latest human input.</span>
    conversation_prompt <span class="token operator">=</span> PromptTemplate<span class="token punctuation">(</span>input_variables<span class="token operator">=</span><span class="token punctuation">[</span><span class="token string">"history"</span><span class="token punctuation">,</span> <span class="token string">"input"</span><span class="token punctuation">]</span><span class="token punctuation">,</span> template<span class="token operator">=</span>prompt_template<span class="token punctuation">)</span>

    <span class="token comment"># Initialize the conversation chain.</span>
    <span class="token comment"># This chain uses the defined prompt, the language model (llm), and the conversation memory.</span>
    conversation_chain <span class="token operator">=</span> ConversationChain<span class="token punctuation">(</span>
        prompt<span class="token operator">=</span>conversation_prompt<span class="token punctuation">,</span>
        llm<span class="token operator">=</span>llm<span class="token punctuation">,</span>
        verbose<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span>
        memory<span class="token operator">=</span>memory<span class="token punctuation">,</span>
    <span class="token punctuation">)</span>
    
    <span class="token comment"># Return the configured conversation chain.</span>
    <span class="token keyword">return</span> conversation_chain</code></pre></div>
<p>이제 <code class="language-text">talk_to_gpt()</code>라는 함수에서 위에서 리턴하는 <code class="language-text">conversation_chain</code>을 활용해 ChatGPT와 대화를 나눈다</p>
<div class="gatsby-highlight" data-language="python"><pre class="language-python"><code class="language-python"><span class="token keyword">def</span> <span class="token function">get_gpt_response</span><span class="token punctuation">(</span>transcript<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token comment"># Talk to the AI Tutor via langchain </span>
    conversation <span class="token operator">=</span> get_chain<span class="token punctuation">(</span><span class="token punctuation">)</span>
    answer <span class="token operator">=</span> conversation<span class="token punctuation">.</span>predict<span class="token punctuation">(</span><span class="token builtin">input</span><span class="token operator">=</span>transcript<span class="token punctuation">)</span>
    
    <span class="token comment"># Return the AI's message content</span>
    <span class="token keyword">return</span> answer</code></pre></div>
<p>이제 리스트를 활용해서 대화 히스토리를 관리할 필요 없이 <code class="language-text">langchain</code>에서 대화이력을 관리해준다. <code class="language-text">verbose=True</code>로 세팅해두면 langchain의 프롬프트를 확인할 수 있다. 스크린샷으로 첨부해본다.</p>
<p><img src="https://i.imgur.com/2qqRJsZ.png" alt="Langchain Prompt"></p>
<p>그리고 <code class="language-text">langchain</code>은 다양한 <a href="https://python.langchain.com/docs/modules/memory/types/" target="_blank" rel="nofollow noopener noreferrer">memory</a>들을 제공한다. 위에서 사용한 <code class="language-text">ConversationBufferMemory</code>는 가장 간단한 메모리인데, 기존에 있던 모든 대화를 <code class="language-text">{history}</code>에 넣어서 프롬프트로 활용하는 식이다. 그냥 로컬 메모리에 저장하는 방식이기 때문에, 이 대화를 만약 15분 길게는 30분씩 이어간다고 한다면, ChatGPT의 토큰수가 초과되는 순간 대화를 더이상 이어갈 수 없게된다.</p>
<p>이를 해결하기 위해 다른 메모리들이 존재한다. 첫번째로 <a href="https://python.langchain.com/docs/modules/memory/types/buffer_window" target="_blank" rel="nofollow noopener noreferrer">ConversationBufferWindowMemory</a>는 변수명에서 나타나는 것처럼 <code class="language-text">window</code>를 활용해서, k를 파라미터로하는 가장 최근의 몇개 대화만 <code class="language-text">{history}</code>에 넣어서 프롬프트로 활용한다. 한시간 정도 대화를 한다면 처음 10분정도의 대화는 뒤에 10분의 대화의 맥락에 큰 영향을 미치지 않는다고 판단할 때 사용하면 좋다.</p>
<p>다음은 <a href="https://python.langchain.com/docs/modules/memory/types/entity_summary_memory" target="_blank" rel="nofollow noopener noreferrer">ConversationEntityMemory</a>. 변수명에서 유추할 수 있듯 기존의 대화 기록에서 특정 주제에 대해 정보를 기억하는 것이다. <code class="language-text">load_memory_variables()</code>이라는 method를 활용해서 대화를 나누는 중 대화 이력에서 해당 정보를 가져와야 할 때 memory에서 LLM을 활용하여 해당 정보를 가져오는 방식이다. <code class="language-text">ConversationEntityMemory</code>는 대화에서 주요 내용을 추출하기 때문에 OpenAI API를 두번 호출하게 된다. 따라서 좀 느리다</p>
<p>다음은 <a href="https://python.langchain.com/docs/modules/memory/types/summary" target="_blank" rel="nofollow noopener noreferrer">ConversationSummary</a>. 변수명에서 보이는 것처럼 대화를 요약해서 <code class="language-text">{history}</code>에 넣어주는 방식이다. 요약할 때 OpenAI API를 추가로 호출해야 하기 때문에 이 역시 느리다. 하지만 대화 내용이 너무 길어서 토큰을 초과할 것 같다면 <code class="language-text">ConversaionSummary</code>를 사용하는 것이 속도는 좀 느리겠지만 정확한 대화를 이어나가는데 훨씬 유리하다.</p>
<p>다음은 <a href="https://python.langchain.com/docs/modules/memory/types/summary_buffer" target="_blank" rel="nofollow noopener noreferrer">ConversationSummaryBuffer</a>. <code class="language-text">ConversationSummary</code>와 <code class="language-text">ConversationBufferWindowMemory</code>를 합쳐둔거라고 보면 된다. 토큰 수를 사용해서 가장 최근의 몇개 대화 내용을 요약해서 <code class="language-text">{history}</code>에 넣어주는 방식이다. <code class="language-text">ConversationSummary</code>가 전체를 요약하는 것과 비교하면 속도는 훨씬 빠르다</p>
<p>다음은 <a href="https://python.langchain.com/docs/modules/memory/types/token_buffer" target="_blank" rel="nofollow noopener noreferrer">ConversationTokenBuffer</a>. <code class="language-text">ConversationSummaryBuffer</code>와 유사하지만 요악을 하지 않고 토큰수를 기반으로 전체 내용을 다 넘긴다. 여기서는 왠지 <code class="language-text">tiktoken</code>으로 연산이 한번 들어갈 것 같으니, 각각의 대화가 너무 길어지는게 아니라면 <code class="language-text">ConversationBufferWindowMemory</code>가 더 유리할 것 같다.</p>
<p>지금은 로컬 메모리에 저장하기 때문에 주피터 노트북을 닫으면 기존의 대화가 날아간다. Langchain에서 DynamoDB나 Firebase 등을 메모리로 쉽게 활용할 수 있는 기능을 지원하기 때문에, 다음 포스트에서는 무료인 Firebase를 활용해서 대화 내용을 저장하고, 노트북을 닫더라도 마지막 대화 시점부터 이야기를 이어나갈 수 있도록 작업해보겠다.</p></div></div></div><div class="Post-module--footer--f8705"><div class="Meta-module--meta--dae0a"><p class="Meta-module--date--4d30d">Published<!-- --> <!-- -->Jan 21, 2024</p></div><div class="Tags-module--tags--18589"><ul class="Tags-module--list--82ae6"><li class="Tags-module--item--52015"><a class="Button-module--button--b1113" href="/tag/llm/">LLM</a></li></ul></div><div class="Author-module--author--1c58d"><p class="Author-module--bio--08950">AI Enthusiast and a Software Engineer<a class="Author-module--twitter--90647" href="https://www.twitter.com/#" rel="noopener noreferrer" target="_blank"><strong>Jason Kang</strong> on Twitter</a></p></div></div><div class="Post-module--comments--d3b99"></div></div></div></div><div id="gatsby-announcer" style="position:absolute;top:0;width:1px;height:1px;padding:0;overflow:hidden;clip:rect(0, 0, 0, 0);white-space:nowrap;border:0" aria-live="assertive" aria-atomic="true"></div></div><script id="gatsby-script-loader">/*<![CDATA[*/window.pagePath="/llm/upgrading-ai-english-tutor-with-langchain";window.___webpackCompilationHash="0fab4eb59768a531201f";/*]]>*/</script><script id="gatsby-chunk-mapping">/*<![CDATA[*/window.___chunkMapping={"app":["/app-74abb6290d31218fe0bf.js"],"component---cache-caches-gatsby-plugin-offline-app-shell-js":["/component---cache-caches-gatsby-plugin-offline-app-shell-js-02abafd21f3ca3501462.js"],"component---src-templates-categories-template-categories-template-tsx":["/component---src-templates-categories-template-categories-template-tsx-b449ea18ac689b1b4d05.js"],"component---src-templates-category-template-category-template-tsx":["/component---src-templates-category-template-category-template-tsx-f25335f9ad4d1e083e1e.js"],"component---src-templates-index-template-index-template-tsx":["/component---src-templates-index-template-index-template-tsx-574bb2c842b72a4f56d6.js"],"component---src-templates-not-found-template-not-found-template-tsx":["/component---src-templates-not-found-template-not-found-template-tsx-87d8cb04f32ef1c28bb0.js"],"component---src-templates-page-template-page-template-tsx":["/component---src-templates-page-template-page-template-tsx-beeff9f32d60af6e299a.js"],"component---src-templates-post-template-post-template-tsx":["/component---src-templates-post-template-post-template-tsx-68607055b92e4eb87137.js"],"component---src-templates-tag-template-tag-template-tsx":["/component---src-templates-tag-template-tag-template-tsx-dbf1278bb80575247891.js"],"component---src-templates-tags-template-tags-template-tsx":["/component---src-templates-tags-template-tags-template-tsx-e89bc401e74db52ece1a.js"]};/*]]>*/</script><script src="/app-74abb6290d31218fe0bf.js" async=""></script><script src="/framework-8a6e3897e8f1c55b7396.js" async=""></script><script src="/webpack-runtime-d65644703f60766379b7.js" async=""></script></body></html>