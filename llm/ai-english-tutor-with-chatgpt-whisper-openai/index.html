<!DOCTYPE html><html lang="en"><head><meta charSet="utf-8"/><meta http-equiv="x-ua-compatible" content="ie=edge"/><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"/><meta name="generator" content="Gatsby 4.25.8"/><meta name="description" content="영어공부를 하고싶은 와이프님 위한 인공지능" data-gatsby-head="true"/><meta name="twitter:card" content="summary_large_image" data-gatsby-head="true"/><meta name="twitter:title" content="ChatGPT + Whisper + OpenAI TTS를 활용한 인공지능 영어공부 - Blog by Jason Kang" data-gatsby-head="true"/><meta name="twitter:description" content="영어공부를 하고싶은 와이프님 위한 인공지능" data-gatsby-head="true"/><meta name="og:title" content="ChatGPT + Whisper + OpenAI TTS를 활용한 인공지능 영어공부 - Blog by Jason Kang" data-gatsby-head="true"/><meta name="og:type" content="website" data-gatsby-head="true"/><meta name="og:description" content="영어공부를 하고싶은 와이프님 위한 인공지능" data-gatsby-head="true"/><meta name="theme-color" content="hsl(31, 92%, 62%)"/><style data-href="/styles.462ccd878fdc76b93a3f.css" data-identity="gatsby-global-css">:after,:before,:root{--color-white:#fff;--color-primary:#5c92ff;--color-secondary:#f7a145;--color-prism-background:#eaeaeb;--color-typographic-base-font:#242933;--color-typographic-link-p-font:#5c92ff;--color-typographic-link-s-font:#f7a145;--color-page-border:#eaeaeb;--color-page-background:#fff;--color-sidebar-border:#eaeaeb;--color-sidebar-border-fade:#fff;--color-contacts-border:#eaeaeb;--color-button-border:#eaeaeb;--color-button-color:#242933;--color-theme-switcher:#3f485a;--color-theme-switcher-hover:#5c92ff}.dark :after,.dark :before,:root.dark{--color-white:#fff;--color-primary:#5c92ff;--color-secondary:#f7a145;--color-prism-background:#191d24;--color-typographic-base-font:#fff;--color-typographic-link-p-font:#5c92ff;--color-typographic-link-s-font:#f7a145;--color-page-border:#3f485a;--color-page-background:#242933;--color-sidebar-border:#3f485a;--color-sidebar-border-fade:#242933;--color-contacts-border:#3f485a;--color-button-border:#3f485a;--color-button-color:#fff;--color-theme-switcher:#eaeaeb;--color-theme-switcher-hover:#5c92ff}html{font-size:100}body{-webkit-font-smoothing:antialiased;-moz-osx-font-smoothing:grayscale;-ms-text-size-adjust:100%;-webkit-text-size-adjust:100%;background:var(--color-page-background);color:var(--color-typographic-base-font);font-size:16px;line-height:1.625;margin:0 0 0 calc(100vw - 100%);text-rendering:optimizelegibility}body,h1,h2,h3,h4,h5,h6{font-family:-apple-system,BlinkMacSystemFont,Segoe UI,Roboto,Oxygen-Sans,Ubuntu,Cantarell,Helvetica Neue,sans-serif}h1,h2,h3,h4,h5,h6{font-weight:600}h1{font-size:40px;line-height:52px;margin-bottom:26px;margin-top:104px}h2{font-size:27px;line-height:39px}h2,h3{margin-bottom:13px;margin-top:52px}h3{font-size:22px;line-height:26px}h4{font-size:19.2px;margin-top:39px}h4,h5{line-height:26px;margin-bottom:13px}h5,h6{font-size:16px;margin-top:65px}h6{line-height:26px;margin-bottom:13px}img{max-width:100%}hr,img{border:0;display:block}hr{background-image:linear-gradient(180deg,transparent 1px,transparent 11px,#242933 0,#242933 15px,transparent 0,transparent 26px);background-size:100% 26px;color:var(--color-typographic-base-font);height:26px;margin:52px auto;width:100px}a{color:var(--color-typographic-link-p-font);text-decoration:none}a:active,a:focus,a:hover{color:var(--color-typographic-link-s-font)}b,strong{font-weight:600}ul{list-style:square;margin-bottom:26px}ul li{margin-bottom:10px;padding:0 5px}p{line-height:26px;margin-bottom:26px}blockquote{font-style:italic;padding:0;text-align:center}figure{display:block;height:auto;width:100%}figcaption{color:var(--color-typographic-base-font);font-size:14px;font-style:italic;line-height:19.5px;margin-bottom:0;margin-top:6.5px;text-align:center}@media screen and (min-width:685px){figure.float-left,figure.float-right{max-width:310px;padding:0 26px}.float-right{float:right}.float-left{float:left}}code[class*=language-],pre[class*=language-]{word-wrap:normal;color:#657b83;font-family:Consolas,Monaco,Andale Mono,Ubuntu Mono,monospace;font-size:1em;-webkit-hyphens:none;hyphens:none;line-height:1.5;tab-size:4;text-align:left;white-space:pre;word-break:normal;word-spacing:normal}pre[class*=language-]{border-radius:.3em;margin:.5em 0;overflow:auto;padding:1em}:not(pre)>code[class*=language-],pre[class*=language-]{background-color:var(--color-prism-background)}:not(pre)>code[class*=language-]{border-radius:.3em;padding:.1em}code[class*=language-] ::selection,code[class*=language-]::selection,pre[class*=language-] ::selection,pre[class*=language-]::selection{background:#073642}.token.cdata,.token.comment,.token.doctype,.token.prolog{color:#93a1a1}.token.punctuation{color:#586e75}.namespace{opacity:.7}.token.boolean,.token.constant,.token.deleted,.token.number,.token.property,.token.symbol,.token.tag{color:#268bd2}.token.attr-name,.token.builtin,.token.char,.token.inserted,.token.selector,.token.string,.token.url{color:#2aa198}.token.entity{background:#eee8d5;color:#657b83;cursor:help}.token.atrule,.token.attr-value,.token.keyword{color:#859900}.token.class-name,.token.function{color:#b58900}.token.important,.token.regex,.token.variable{color:#cb4b16}.token.bold,.token.important{font-weight:700}.token.italic{font-style:italic}.Feed-module--feed--a6204 .Feed-module--item--c7a63{margin-bottom:32.5px}.Feed-module--feed--a6204 .Feed-module--item--c7a63:last-child{margin-bottom:13px}.Feed-module--feed--a6204 .Feed-module--item--c7a63 .Feed-module--title--f252f{font-size:27px;line-height:39px;margin-bottom:13px;margin-top:0}.Feed-module--feed--a6204 .Feed-module--item--c7a63 .Feed-module--title--f252f .Feed-module--link--6123b{color:var(--color-typographic-base-font)}.Feed-module--feed--a6204 .Feed-module--item--c7a63 .Feed-module--title--f252f .Feed-module--link--6123b:focus,.Feed-module--feed--a6204 .Feed-module--item--c7a63 .Feed-module--title--f252f .Feed-module--link--6123b:hover{border-bottom:1px solid #242933;color:var(--color-typographic-base-font)}.Feed-module--feed--a6204 .Feed-module--item--c7a63 .Feed-module--description--57348{font-size:16px;line-height:26px;margin-bottom:19.5px}.Feed-module--feed--a6204 .Feed-module--item--c7a63 .Feed-module--meta--250c2 .Feed-module--time--72864{color:var(--color-typographic-base-font);font-size:14px;font-weight:600;text-transform:uppercase}.Feed-module--feed--a6204 .Feed-module--item--c7a63 .Feed-module--meta--250c2 .Feed-module--divider--81a18{margin:0 13px}.Feed-module--feed--a6204 .Feed-module--item--c7a63 .Feed-module--meta--250c2 .Feed-module--category--59f58 .Feed-module--link--6123b{color:var(--color-secondary);font-size:14px;font-weight:600;text-transform:uppercase}.Feed-module--feed--a6204 .Feed-module--item--c7a63 .Feed-module--meta--250c2 .Feed-module--category--59f58 .Feed-module--link--6123b:focus,.Feed-module--feed--a6204 .Feed-module--item--c7a63 .Feed-module--meta--250c2 .Feed-module--category--59f58 .Feed-module--link--6123b:hover{color:#5c92ff}.Feed-module--feed--a6204 .Feed-module--item--c7a63 .Feed-module--more--51a4e{color:var(--color-primary);font-size:16px}.Feed-module--feed--a6204 .Feed-module--item--c7a63 .Feed-module--more--51a4e:focus,.Feed-module--feed--a6204 .Feed-module--item--c7a63 .Feed-module--more--51a4e:hover{border-bottom:1px solid #5c92ff;color:var(--color-primary)}.Layout-module--layout--2c933{margin-left:auto;margin-right:auto;max-width:1070px}.Layout-module--layout--2c933:before{content:"";display:table}.Layout-module--layout--2c933:after{clear:both;content:"";display:table}.Page-module--page--24e03{margin-bottom:52px}.Page-module--page--24e03 .Page-module--inner--4b31d{padding:26px 19.5px 0}.Page-module--page--24e03 .Page-module--title--90338{font-size:40px;font-weight:600;line-height:52px;margin-bottom:37.7px;margin-top:0}.Page-module--page--24e03 .Page-module--body--561c4{font-size:16px;line-height:26px;margin:0 0 26px}@media screen and (min-width:685px){.Page-module--page--24e03{width:calc(58.275% - 12.5px)}.Page-module--page--24e03:nth-child(1n){clear:none;float:left;margin-right:30px}.Page-module--page--24e03:last-child{margin-right:0}.Page-module--page--24e03:nth-child(12n){float:right;margin-right:0}.Page-module--page--24e03:nth-child(12n+1){clear:both}.Page-module--page--24e03 .Page-module--inner--4b31d{padding:32.5px 19.5px 0}}@media screen and (min-width:960px){.Page-module--page--24e03{width:calc(66.6% - 10px)}.Page-module--page--24e03:nth-child(1n){clear:none;float:left;margin-right:30px}.Page-module--page--24e03:last-child{margin-right:0}.Page-module--page--24e03:nth-child(3n){float:right;margin-right:0}.Page-module--page--24e03:nth-child(3n+1){clear:both}.Page-module--page--24e03 .Page-module--inner--4b31d{padding:39px 26px 0}}.Pagination-module--pagination--d61cb{display:flex;margin-top:52px}.Pagination-module--pagination--d61cb .Pagination-module--previous--4a76b{text-align:left;width:50%}.Pagination-module--pagination--d61cb .Pagination-module--previous--4a76b .Pagination-module--previousLink--5590d{color:var(--color-secondary);font-size:26px;font-weight:700}.Pagination-module--pagination--d61cb .Pagination-module--previous--4a76b .Pagination-module--previousLink--5590d:focus,.Pagination-module--pagination--d61cb .Pagination-module--previous--4a76b .Pagination-module--previousLink--5590d:hover{color:var(--color-primary)}.Pagination-module--pagination--d61cb .Pagination-module--previous--4a76b .Pagination-module--previousLink--5590d.Pagination-module--disable--7e105{color:#3f485a;pointer-events:none}.Pagination-module--pagination--d61cb .Pagination-module--next--1cab8{text-align:right;width:50%}.Pagination-module--pagination--d61cb .Pagination-module--next--1cab8 .Pagination-module--nextLink--532ff{color:var(--color-secondary);font-size:26px;font-weight:700}.Pagination-module--pagination--d61cb .Pagination-module--next--1cab8 .Pagination-module--nextLink--532ff:focus,.Pagination-module--pagination--d61cb .Pagination-module--next--1cab8 .Pagination-module--nextLink--532ff:hover{color:var(--color-primary)}.Pagination-module--pagination--d61cb .Pagination-module--next--1cab8 .Pagination-module--nextLink--532ff.Pagination-module--disable--7e105{color:#3f485a;pointer-events:none}.Button-module--button--b1113{border:1px solid var(--color-button-border);border-radius:20px;color:var(--color-button-color);display:inline-block;font-size:16px;font-weight:400;height:40px;line-height:40px;margin-left:auto;margin-right:auto;padding:0 26px;text-align:center;text-decoration:none}.Button-module--button--b1113:focus,.Button-module--button--b1113:hover{color:#5c92ff}.ThemeSwitcher-module--themeSwitcher--8a77f{--color:var(--color-theme-switcher)}.ThemeSwitcher-module--themeSwitcher--8a77f .ThemeSwitcher-module--button--7cb7b{align-items:center;background:transparent;border:0;cursor:pointer;display:flex;justify-content:center;outline:0}.ThemeSwitcher-module--themeSwitcher--8a77f .ThemeSwitcher-module--button--7cb7b svg{stroke:var(--color);pointer-events:none;transition:stroke .4s}.ThemeSwitcher-module--themeSwitcher--8a77f .ThemeSwitcher-module--button--7cb7b:hover{--color:var(--color-theme-switcher-hover)}.ThemeSwitcher-module--themeSwitcher--8a77f .ThemeSwitcher-module--moon--10537{stroke-dasharray:0 1px;opacity:0;transition:stroke-dasharray .2s ease-in,opacity .4s ease-in}.ThemeSwitcher-module--themeSwitcher--8a77f .ThemeSwitcher-module--sun--2163a{stroke-dasharray:1px 1px;opacity:1;transition:stroke-dasharray .2s ease-in,opacity .4s ease-in}.ThemeSwitcher-module--themeSwitcher--8a77f.ThemeSwitcher-module--dark--6db0c .ThemeSwitcher-module--moon--10537{stroke-dasharray:1px 1px;opacity:1}.ThemeSwitcher-module--themeSwitcher--8a77f.ThemeSwitcher-module--dark--6db0c .ThemeSwitcher-module--sun--2163a{stroke-dasharray:0 1px;opacity:0}.Author-module--author--cbd31 .Author-module--photo--9787b{background-clip:padding-box;border-radius:50%;display:inline-block;height:75px;margin-bottom:0;width:75px}.Author-module--author--cbd31 .Author-module--photo--9787b img{border-radius:50%}.Author-module--author--cbd31 .Author-module--title--cf7e5{font-size:18px;font-weight:600;line-height:29.25px;margin:0}.Author-module--author--cbd31 .Author-module--title--cf7e5 .Author-module--link--09c17,.Author-module--author--cbd31 .Author-module--title--cf7e5 .Author-module--link--09c17:focus,.Author-module--author--cbd31 .Author-module--title--cf7e5 .Author-module--link--09c17:hover{color:var(--color-typographic-base-font)}.Author-module--author--cbd31 .Author-module--subtitle--86ec5{color:#7f8ba4;line-height:26px;margin-bottom:26px}.Author-module--author--cbd31 .Author-module--titleContainer--4f576{align-items:center;display:flex;justify-content:space-between;margin:13px 0}.Icon-module--icon--1d7da{fill:currentcolor;-webkit-font-smoothing:antialiased;-moz-osx-font-smoothing:grayscale;speak:none;stroke:currentcolor;stroke-width:0;display:inline-block;font-style:normal;font-variant:normal;font-weight:400;height:1em;line-height:1em;text-align:center;text-transform:none;width:1em}.Contacts-module--contacts--09178{margin-bottom:26px}.Contacts-module--contacts--09178 .Contacts-module--list--9670b{display:flex;flex-flow:row wrap;flex-grow:0;flex-shrink:0;list-style:none;margin:13px 0;max-width:165px;padding:0}.Contacts-module--contacts--09178 .Contacts-module--list--9670b .Contacts-module--item--f9cb0{align-content:center;align-items:center;border:1px solid var(--color-contacts-border);border-radius:50%;display:flex;height:40px;justify-content:center;line-height:40px;margin:6.5px;padding:0;text-align:center;width:40px}.Contacts-module--contacts--09178 .Contacts-module--list--9670b .Contacts-module--item--f9cb0:nth-child(3n+1){margin-left:0}.Contacts-module--contacts--09178 .Contacts-module--list--9670b .Contacts-module--item--f9cb0 .Contacts-module--link--de1e0{border:0;color:var(--color-typographic-base-font);cursor:pointer;display:flex}.Contacts-module--contacts--09178 .Contacts-module--list--9670b .Contacts-module--item--f9cb0 .Contacts-module--link--de1e0:focus,.Contacts-module--contacts--09178 .Contacts-module--list--9670b .Contacts-module--item--f9cb0 .Contacts-module--link--de1e0:hover{color:var(--color-typographic-link-p-font)}.Copyright-module--copyright--2c602{color:#7f8ba4;font-size:14px}.Menu-module--menu--113a9{margin-bottom:26px}.Menu-module--menu--113a9 .Menu-module--list--e1ae3{list-style:none;margin:0;padding:0}.Menu-module--menu--113a9 .Menu-module--list--e1ae3 .Menu-module--item--8b679{margin:13px 0;padding:0}.Menu-module--menu--113a9 .Menu-module--list--e1ae3 .Menu-module--item--8b679 .Menu-module--link--a6f02{border:0;color:var(--color-typographic-base-font);font-size:16px;font-weight:400}.Menu-module--menu--113a9 .Menu-module--list--e1ae3 .Menu-module--item--8b679 .Menu-module--link--a6f02:focus,.Menu-module--menu--113a9 .Menu-module--list--e1ae3 .Menu-module--item--8b679 .Menu-module--link--a6f02:hover{border-bottom:1px solid #5c92ff;color:#5c92ff}.Menu-module--menu--113a9 .Menu-module--list--e1ae3 .Menu-module--item--8b679 .Menu-module--link--a6f02.Menu-module--active--6cb74{border-bottom:1px solid var(--color-typographic-base-font);color:var(--color-typographic-base-font)}.Sidebar-module--sidebar--1bfa1{width:100%}.Sidebar-module--sidebar--1bfa1 .Sidebar-module--inner--344d0{padding:26px 19.5px 0;position:relative}.Sidebar-module--sidebar--1bfa1 .Sidebar-module--inner--344d0:after{background:var(--color-sidebar-border);background:linear-gradient(to bottom,var(--color-sidebar-border) 0,var(--color-sidebar-border) 48%,var(--color-sidebar-border-fade) 100%)}@media screen and (min-width:685px){.Sidebar-module--sidebar--1bfa1{width:calc(41.625% - 17.5px)}.Sidebar-module--sidebar--1bfa1:nth-child(1n){clear:none;float:left;margin-right:30px}.Sidebar-module--sidebar--1bfa1:last-child{margin-right:0}.Sidebar-module--sidebar--1bfa1:nth-child(12n){float:right;margin-right:0}.Sidebar-module--sidebar--1bfa1:nth-child(12n+1){clear:both}.Sidebar-module--sidebar--1bfa1 .Sidebar-module--inner--344d0{padding:32.5px 19.5px 0}.Sidebar-module--sidebar--1bfa1 .Sidebar-module--inner--344d0:after{bottom:0;content:"";height:540px;position:absolute;right:-10px;top:30px;width:1px}}@media screen and (min-width:960px){.Sidebar-module--sidebar--1bfa1{width:calc(33.3% - 20px)}.Sidebar-module--sidebar--1bfa1:nth-child(1n){clear:none;float:left;margin-right:30px}.Sidebar-module--sidebar--1bfa1:last-child{margin-right:0}.Sidebar-module--sidebar--1bfa1:nth-child(3n){float:right;margin-right:0}.Sidebar-module--sidebar--1bfa1:nth-child(3n+1){clear:both}.Sidebar-module--sidebar--1bfa1 .Sidebar-module--inner--344d0{padding:39px}}.Author-module--author--1c58d{border-top:1px solid var(--color-page-border);line-height:26px;margin-bottom:52px;margin-top:26px;max-width:640px;padding-top:26px}.Author-module--author--1c58d .Author-module--bio--08950 .Author-module--twitter--90647{display:block;text-decoration:underline}.Author-module--author--1c58d .Author-module--bio--08950 .Author-module--twitter--90647:focus,.Author-module--author--1c58d .Author-module--bio--08950 .Author-module--twitter--90647:hover{color:var(--color-typographic-link-s-font)}@media screen and (min-width:685px){.Author-module--author--1c58d{margin-left:auto;margin-right:auto}}.Content-module--content--80d58{margin:0 auto;max-width:945px;padding:0 13px}.Content-module--content--80d58 .Content-module--title--09504{font-size:32px;font-weight:600;line-height:42.9px;margin:26px auto 0;max-width:640px;text-align:center}.Content-module--content--80d58 .Content-module--body--726c2 figure{margin-bottom:26px}.Content-module--content--80d58 .Content-module--body--726c2 figure blockquote{font-style:italic;margin-top:0;padding:26px 0;text-align:center}.Content-module--content--80d58 .Content-module--body--726c2 figure blockquote p{font-size:26.9072px;line-height:39px;margin-bottom:26px;margin-top:0;max-width:640px}.Content-module--content--80d58 .Content-module--body--726c2 a{text-decoration:underline}.Content-module--content--80d58 .Content-module--body--726c2 *{margin-left:auto;margin-right:auto;max-width:640px}.Content-module--content--80d58 .Content-module--body--726c2 h2>a{visibility:hidden}.Content-module--content--80d58 .Content-module--body--726c2 h2>a>svg{fill:var(--color-typographic-base-font)}.Content-module--content--80d58 .Content-module--body--726c2 img{max-width:100%}@media screen and (min-width:960px){.Content-module--content--80d58{padding:0}.Content-module--content--80d58 .Content-module--title--09504{font-size:48px;line-height:58.5px;margin-bottom:39px;margin-top:58.5px}.Content-module--content--80d58 .Content-module--body--726c2,.Content-module--content--80d58 .Content-module--body--726c2 p{font-size:18px;line-height:29.25px;margin-bottom:29.25px}.Content-module--content--80d58 .Content-module--body--726c2 h2>a{padding-right:13px;visibility:unset}}.Meta-module--meta--dae0a .Meta-module--date--4d30d{font-style:italic}.Tags-module--tags--18589{margin-bottom:13px}.Tags-module--tags--18589 .Tags-module--list--82ae6{list-style:none;padding:0}.Tags-module--tags--18589 .Tags-module--list--82ae6 .Tags-module--item--52015{display:inline-block;margin:6.5px 0}@media screen and (min-width:685px){.Tags-module--tags--18589 .Tags-module--list--82ae6 .Tags-module--item--52015:first-child{margin-left:0;padding-left:0}}.Post-module--post--3a994 .Post-module--content--3c6e5{margin:0 auto}.Post-module--post--3a994 .Post-module--comments--d3b99,.Post-module--post--3a994 .Post-module--footer--f8705{margin:0 auto;max-width:640px;padding:0 13px}.Post-module--post--3a994 .Post-module--buttons--2972d{align-items:center;display:flex;justify-content:center;margin:26px 0 0;text-align:center}.Post-module--post--3a994 .Post-module--buttons--2972d .Post-module--buttonArticles--d793a{margin:0 13px 0 0}@media screen and (min-width:960px){.Post-module--post--3a994 .Post-module--comments--d3b99,.Post-module--post--3a994 .Post-module--footer--f8705{padding:0}.Post-module--post--3a994 .Post-module--buttons--2972d{left:30px;margin:0 13px 0 0;max-width:none;position:fixed;top:30px}}</style><title data-gatsby-head="true">ChatGPT + Whisper + OpenAI TTS를 활용한 인공지능 영어공부 - Blog by Jason Kang</title><script async="" src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script><script>            
              (adsbygoogle = window.adsbygoogle || []).push({
                google_ad_client: "ca-pub-2002611361597206",
                enable_page_level_ads: true
              });
          </script><link rel="preconnect" href="https://www.googletagmanager.com"/><link rel="dns-prefetch" href="https://www.googletagmanager.com"/><script async="" src="https://www.googletagmanager.com/gtag/js?id=G-8BHCT1V21F"></script><script>
      
      
      if(true) {
        window.dataLayer = window.dataLayer || [];
        function gtag(){dataLayer.push(arguments);}
        gtag('js', new Date());

        gtag('config', 'G-8BHCT1V21F', {"send_page_view":false});
      }
      </script><link rel="alternate" type="application/rss+xml" title="Blog by Jason Kang" href="/rss.xml"/><style type="text/css">
    .anchor.before {
      position: absolute;
      top: 0;
      left: 0;
      transform: translateX(-100%);
      padding-right: 4px;
    }
    .anchor.after {
      display: inline-block;
      padding-left: 4px;
    }
    h1 .anchor svg,
    h2 .anchor svg,
    h3 .anchor svg,
    h4 .anchor svg,
    h5 .anchor svg,
    h6 .anchor svg {
      visibility: hidden;
    }
    h1:hover .anchor svg,
    h2:hover .anchor svg,
    h3:hover .anchor svg,
    h4:hover .anchor svg,
    h5:hover .anchor svg,
    h6:hover .anchor svg,
    h1 .anchor:focus svg,
    h2 .anchor:focus svg,
    h3 .anchor:focus svg,
    h4 .anchor:focus svg,
    h5 .anchor:focus svg,
    h6 .anchor:focus svg {
      visibility: visible;
    }
  </style><script>
    document.addEventListener("DOMContentLoaded", function(event) {
      var hash = window.decodeURI(location.hash.replace('#', ''))
      if (hash !== '') {
        var element = document.getElementById(hash)
        if (element) {
          var scrollTop = window.pageYOffset || document.documentElement.scrollTop || document.body.scrollTop
          var clientTop = document.documentElement.clientTop || document.body.clientTop || 0
          var offset = element.getBoundingClientRect().top + scrollTop - clientTop
          // Wait for the browser to finish rendering before scrolling.
          setTimeout((function() {
            window.scrollTo(0, offset - 0)
          }), 0)
        }
      }
    })
  </script><link rel="sitemap" type="application/xml" href="/sitemap/sitemap-index.xml"/><link rel="icon" href="/favicon-32x32.png?v=110dbcaf7b73f2d646b07137b9e3af54" type="image/png"/><link rel="manifest" href="/manifest.webmanifest" crossorigin="anonymous"/><link rel="apple-touch-icon" sizes="48x48" href="/icons/icon-48x48.png?v=110dbcaf7b73f2d646b07137b9e3af54"/><link rel="apple-touch-icon" sizes="72x72" href="/icons/icon-72x72.png?v=110dbcaf7b73f2d646b07137b9e3af54"/><link rel="apple-touch-icon" sizes="96x96" href="/icons/icon-96x96.png?v=110dbcaf7b73f2d646b07137b9e3af54"/><link rel="apple-touch-icon" sizes="144x144" href="/icons/icon-144x144.png?v=110dbcaf7b73f2d646b07137b9e3af54"/><link rel="apple-touch-icon" sizes="192x192" href="/icons/icon-192x192.png?v=110dbcaf7b73f2d646b07137b9e3af54"/><link rel="apple-touch-icon" sizes="256x256" href="/icons/icon-256x256.png?v=110dbcaf7b73f2d646b07137b9e3af54"/><link rel="apple-touch-icon" sizes="384x384" href="/icons/icon-384x384.png?v=110dbcaf7b73f2d646b07137b9e3af54"/><link rel="apple-touch-icon" sizes="512x512" href="/icons/icon-512x512.png?v=110dbcaf7b73f2d646b07137b9e3af54"/><style>.gatsby-image-wrapper{position:relative;overflow:hidden}.gatsby-image-wrapper picture.object-fit-polyfill{position:static!important}.gatsby-image-wrapper img{bottom:0;height:100%;left:0;margin:0;max-width:none;padding:0;position:absolute;right:0;top:0;width:100%;object-fit:cover}.gatsby-image-wrapper [data-main-image]{opacity:0;transform:translateZ(0);transition:opacity .25s linear;will-change:opacity}.gatsby-image-wrapper-constrained{display:inline-block;vertical-align:top}</style><noscript><style>.gatsby-image-wrapper noscript [data-main-image]{opacity:1!important}.gatsby-image-wrapper [data-placeholder-image]{opacity:0!important}</style></noscript><script type="module">const e="undefined"!=typeof HTMLImageElement&&"loading"in HTMLImageElement.prototype;e&&document.body.addEventListener("load",(function(e){const t=e.target;if(void 0===t.dataset.mainImage)return;if(void 0===t.dataset.gatsbyImageSsr)return;let a=null,n=t;for(;null===a&&n;)void 0!==n.parentNode.dataset.gatsbyImageWrapper&&(a=n.parentNode),n=n.parentNode;const o=a.querySelector("[data-placeholder-image]"),r=new Image;r.src=t.currentSrc,r.decode().catch((()=>{})).then((()=>{t.style.opacity=1,o&&(o.style.opacity=0,o.style.transition="opacity 500ms linear")}))}),!0);</script></head><body><script>
          void function() {
            var cachedMode;

            try {
              var preferredTheme = JSON.parse(localStorage.getItem('diesel:theme-atom'));

              if (preferredTheme && preferredTheme.mode) {
                cachedMode = preferredTheme.mode;
              }
            } catch (err) { }

            function setTheme(newTheme) {
              document.documentElement.className = newTheme;
            }

            var darkQuery = window.matchMedia('(prefers-color-scheme: dark)');

            setTheme(cachedMode || (darkQuery.matches ? 'dark' : 'light'));
          }()
        </script><div id="___gatsby"><div style="outline:none" tabindex="-1" id="gatsby-focus-wrapper"><div class="Layout-module--layout--2c933"><div class="Post-module--post--3a994"><div class="Post-module--buttons--2972d"><a class="Button-module--button--b1113 Post-module--buttonArticles--d793a" href="/">All Articles</a></div><div class="Post-module--content--3c6e5"><div class="Content-module--content--80d58"><h1 class="Content-module--title--09504">ChatGPT + Whisper + OpenAI TTS를 활용한 인공지능 영어공부</h1><div class="Content-module--body--726c2"><p>요즘 갑자기 영어공부에 관심을 갖게된 와이프님께서 하루에 10분정도 영어로 대화하기를 제안했다. 하면 충분히 할 수 있지만 뭔가 어색할 것 같기도하고, 사실 나도 영어를 할줄만 알지 가르쳐본적은 많지 않아서 “굳이 나랑 하는게 의미가 있나”라는 생각이 들었다. 그러던 중에 OpenAI DevDay에서 TTS를 열심히 홍보했던 Sam Altman의 영상이 생각나서 인공지능으로 영어를 가르쳐주는 봇을 만들어보기로 했다.</p>
<p>LLM과 대화는 ChatGPT의 <a href="https://platform.openai.com/docs/guides/text-generation/chat-completions-api" target="_blank" rel="nofollow noopener noreferrer">Chat Completions API</a>를 사용하면 가능하니, <a href="https://openai.com/research/whisper" target="_blank" rel="nofollow noopener noreferrer">Whisper</a>를 사용해서 와이프님께서 말하는 내용을 텍스트로 바꿔서 ChatGPT에게 넘겨주기만 하면 된다.</p>
<p>Chat Completions API를 사용할 때는 system - user - assistant - user - assistant와 같은 순으로, 처음에 <code class="language-text">system prompt</code>를 활용해서 역할을 안내하면, 그 후에는 user와 assistant가 대화를 나누는 구조이다. 그래서 system propmt를 먼저 작성했다.</p>
<div class="gatsby-highlight" data-language="python"><pre class="language-python"><code class="language-python">system_prompt <span class="token operator">=</span> <span class="token triple-quoted-string string">"""
You are an experienced English tutor who graduated from Harvard University in Boston.
You are talking to a student who wants to practice speaking English. 
Help them practice speaking English by talking to your student and 
While talking to your student, help your student how to say what they would like to say.
The answer must be formatted as a JSON string
"""</span></code></pre></div>
<p>Ringle을 사용하면 아이비리그 학생들한테 영어를 배울 수 있으니, 하버드 대학을 졸업했다는 role을 부여해보았다. 그리고 학생과 대화를 하고, 학생들이 말하는 것을 듣고, 어떻게 말하면 좋을지 개선해달라고 요청했다. 이제 작성한 <code class="language-text">system_prompt</code>를 활용해서 ChatCompletions API에 넘겨준다</p>
<div class="gatsby-highlight" data-language="python"><pre class="language-python"><code class="language-python"><span class="token keyword">def</span> <span class="token function">get_gpt_response</span><span class="token punctuation">(</span>transcript<span class="token punctuation">)</span><span class="token punctuation">:</span>
  
  system_message <span class="token operator">=</span> <span class="token punctuation">{</span>
    <span class="token string">"role"</span><span class="token punctuation">:</span> <span class="token string">"system"</span><span class="token punctuation">,</span> 
    <span class="token string">"content"</span><span class="token punctuation">:</span> system_prompt<span class="token punctuation">.</span>replace<span class="token punctuation">(</span><span class="token string">"\n"</span><span class="token punctuation">,</span> <span class="token string">""</span><span class="token punctuation">)</span>
  <span class="token punctuation">}</span>
  message_list <span class="token operator">=</span> <span class="token punctuation">[</span>system_message<span class="token punctuation">,</span> <span class="token punctuation">{</span><span class="token string">"role"</span><span class="token punctuation">:</span> <span class="token string">"user"</span><span class="token punctuation">,</span> <span class="token string">"content"</span><span class="token punctuation">:</span> transcript<span class="token punctuation">}</span><span class="token punctuation">]</span>

  response <span class="token operator">=</span> client<span class="token punctuation">.</span>chat<span class="token punctuation">.</span>completions<span class="token punctuation">.</span>create<span class="token punctuation">(</span>
    model<span class="token operator">=</span>gpt_model_name<span class="token punctuation">,</span>
    response_format<span class="token operator">=</span><span class="token punctuation">{</span> <span class="token string">"type"</span><span class="token punctuation">:</span> <span class="token string">"json_object"</span> <span class="token punctuation">}</span><span class="token punctuation">,</span>
    messages<span class="token operator">=</span>message_list
  <span class="token punctuation">)</span>
  
  <span class="token keyword">return</span> response<span class="token punctuation">.</span>choices<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">.</span>message<span class="token punctuation">.</span>content</code></pre></div>
<p>Chat Completions Api를 활용할 때 <a href="https://platform.openai.com/docs/guides/text-generation/json-mode" target="_blank" rel="nofollow noopener noreferrer">JSON Mode</a>가 엄청 유용한데, JSON mode를 사용하려면 프롬프트에 JSON이 꼭 명시되어야 한다. 그렇지 않으면 JSON을 프롬프트에 언급해달라고 하는 에러메세지가 발생한다. 추가로 <code class="language-text">systemp_prompt</code>에서 <code class="language-text">\n</code>을 제거하는 이유는 토큰 갯수를 줄이기 위해서이다. 대세에 큰 영향은 없을수도 있지만 조금의 비용저감이 가능하다.</p>
<p><img src="https://i.imgur.com/2WP6I6k.png" alt="talking-to-chat-gpt"></p>
<p>한 번 대화를 나눠보니 정상적으로 잘 작동한다. 이제 대화를 어딘가에 저장해서 대화 thread를 만들어야한다. 모든 대화 내용을 계속 넘겨주면 언젠가는 토큰을 초과할 수 있으니, 가장 최근 대화 10개정도만 전달할 생각이다. 서로 가장 최근에 주고 받은 문장 5개정도만 주고받아도, 충분히 문맥을 파악할 수 있을거라고 생각한다.</p>
<div class="gatsby-highlight" data-language="python"><pre class="language-python"><code class="language-python"><span class="token keyword">import</span> json

history <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span> <span class="token comment"># 대화 내용을 저장하는 메모리</span>

<span class="token keyword">def</span> <span class="token function">talk_to_gpt</span><span class="token punctuation">(</span>user_input<span class="token punctuation">)</span><span class="token punctuation">:</span>
  gpt_response <span class="token operator">=</span> get_gpt_response<span class="token punctuation">(</span>user_input<span class="token punctuation">,</span> history<span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">10</span><span class="token punctuation">:</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
  gpt_response <span class="token operator">=</span> json<span class="token punctuation">.</span>loads<span class="token punctuation">(</span>gpt_response<span class="token punctuation">)</span>
  gpt_response <span class="token operator">=</span> gpt_response<span class="token punctuation">[</span><span class="token string">'response'</span><span class="token punctuation">]</span>
  history<span class="token punctuation">.</span>extend<span class="token punctuation">(</span><span class="token punctuation">[</span>
      <span class="token punctuation">{</span><span class="token string">"role"</span><span class="token punctuation">:</span> <span class="token string">"user"</span><span class="token punctuation">,</span> <span class="token string">"content"</span><span class="token punctuation">:</span> user_input<span class="token punctuation">}</span><span class="token punctuation">,</span> 
      <span class="token punctuation">{</span><span class="token string">"role"</span><span class="token punctuation">:</span> <span class="token string">"assistant"</span><span class="token punctuation">,</span> <span class="token string">"content"</span><span class="token punctuation">:</span> gpt_response<span class="token punctuation">}</span>
  <span class="token punctuation">]</span><span class="token punctuation">)</span></code></pre></div>
<p><code class="language-text">talk_to_gpt('what would you like to do this weekend?')</code>와 같이 질문하면, <code class="language-text">gpt_response</code>에 담겨오는 LLM의 응답을 <code class="language-text">history</code>에 저장하는 형식이다. <code class="language-text">history</code>에 추가할 때는 <code class="language-text">.append()</code>를 2번 호출하는 것 보다, <code class="language-text">.extend()</code>를 사용해서 리스트를 넘기는 편이 함수 호출도 줄이고, 가독성에도 유리하다고 판단했다. FILO의 느낌이니 stack을 활용하는 것도 좋겠지만, stack에서 꺼낸 대화 thread를 다시 stack에 넣어줘야하기 때문에, stack처럼 <code class="language-text">.pop()</code>하는 느낌보다는 <code class="language-text">.read()</code>가 조금 더 유리하다고 생각한다.</p>
<p>사용자가 이어서 대화를 나누고자 하면 <code class="language-text">history</code>에 저장된 가장 최근 대화 10개를 불러와서 LLM에 넘겨준다. 이제 <code class="language-text">get_gpt_response()</code>도 <code class="language-text">history</code>를 parameter로 사용할 수 있도록 수정해야한다.</p>
<div class="gatsby-highlight" data-language="python"><pre class="language-python"><code class="language-python"><span class="token keyword">def</span> <span class="token function">get_gpt_response</span><span class="token punctuation">(</span>transcript<span class="token punctuation">,</span> history<span class="token punctuation">)</span><span class="token punctuation">:</span>
  
  system_message <span class="token operator">=</span> <span class="token punctuation">{</span>
    <span class="token string">"role"</span><span class="token punctuation">:</span> <span class="token string">"system"</span><span class="token punctuation">,</span> 
    <span class="token string">"content"</span><span class="token punctuation">:</span> system_prompt<span class="token punctuation">.</span>replace<span class="token punctuation">(</span><span class="token string">"\n"</span><span class="token punctuation">,</span> <span class="token string">""</span><span class="token punctuation">)</span>
  <span class="token punctuation">}</span>
  
  message_list <span class="token operator">=</span> <span class="token punctuation">[</span>system_message<span class="token punctuation">]</span>
  message_list<span class="token punctuation">.</span>extend<span class="token punctuation">(</span>history<span class="token punctuation">)</span> <span class="token comment"># 과거 대화 이력을 먼저 추가한 후에 새로운 유저 인풋을 추가한다</span>
  message_list<span class="token punctuation">.</span>append<span class="token punctuation">(</span><span class="token punctuation">{</span><span class="token string">"role"</span><span class="token punctuation">:</span> <span class="token string">"user"</span><span class="token punctuation">,</span> <span class="token string">"content"</span><span class="token punctuation">:</span> transcript<span class="token punctuation">}</span><span class="token punctuation">)</span>

  response <span class="token operator">=</span> client<span class="token punctuation">.</span>chat<span class="token punctuation">.</span>completions<span class="token punctuation">.</span>create<span class="token punctuation">(</span>
    model<span class="token operator">=</span>gpt_model_name<span class="token punctuation">,</span>
    response_format<span class="token operator">=</span><span class="token punctuation">{</span> <span class="token string">"type"</span><span class="token punctuation">:</span> <span class="token string">"json_object"</span> <span class="token punctuation">}</span><span class="token punctuation">,</span>
    messages<span class="token operator">=</span>message_list
  <span class="token punctuation">)</span>
  
  <span class="token keyword">return</span> response<span class="token punctuation">.</span>choices<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">.</span>message<span class="token punctuation">.</span>content</code></pre></div>
<p><img src="https://i.imgur.com/NwwOWdF.png" alt="talking-to-gpt-with-talk-to-gpt"></p>
<p>이런식으로 대화를 잘 나눴고, <code class="language-text">history</code>에도 잘 저장됐다.</p>
<p><img src="https://i.imgur.com/faAAFSv.png" alt="chat-history-with-chatgpt"></p>
<p>이제 텍스트 인풋 대신 음성을 넘겨줘본다. 마이크를 사용해서 녹음하는 기능을 파이썬으로 구현하기 전에, 맥북의 녹음기를 사용해서 음성파일을 생성하고, 해당 음성파일을 사용해서 대화를 하는 방식을 먼저 시도해봤다. 우선 <a href="https://platform.openai.com/docs/guides/speech-to-text/speech-to-text" target="_blank" rel="nofollow noopener noreferrer">공식문서</a>에 나온대로 Whisper 사용을 준비하면</p>
<div class="gatsby-highlight" data-language="python"><pre class="language-python"><code class="language-python"><span class="token keyword">def</span> <span class="token function">get_transcript</span><span class="token punctuation">(</span>file_path<span class="token punctuation">)</span><span class="token punctuation">:</span>
  audio_file<span class="token operator">=</span> <span class="token builtin">open</span><span class="token punctuation">(</span>file_path<span class="token punctuation">,</span> <span class="token string">"rb"</span><span class="token punctuation">)</span>
  transcript <span class="token operator">=</span> client<span class="token punctuation">.</span>audio<span class="token punctuation">.</span>transcriptions<span class="token punctuation">.</span>create<span class="token punctuation">(</span>
      model<span class="token operator">=</span><span class="token string">"whisper-1"</span><span class="token punctuation">,</span>
      <span class="token builtin">file</span><span class="token operator">=</span>audio_file<span class="token punctuation">,</span>
      response_format<span class="token operator">=</span><span class="token string">"text"</span>
  <span class="token punctuation">)</span>
  <span class="token keyword">return</span> transcript</code></pre></div>
<p>음성파일을 넘겨줘서 테스트 해봤다.</p>
<p><img src="https://i.imgur.com/Z1ALo1N.png" alt="testing-local-audio-with-whisper"></p>
<p>매우 잘된다.</p>
<ol>
<li>이제 녹음된 파일의 경로를 <code class="language-text">talk_to_gpt()</code>에 파라미터로 넘겨주고,</li>
<li><code class="language-text">talk_to_gpt()</code>에서는 <code class="language-text">get_transcript()</code>를 호출해서 STT를 진행하고</li>
<li>script를 <code class="language-text">get_gpt_response()</code>에 넘겨줘서 대화를 하면된다.</li>
</ol>
<div class="gatsby-highlight" data-language="python"><pre class="language-python"><code class="language-python"><span class="token keyword">def</span> <span class="token function">talk_to_gpt</span><span class="token punctuation">(</span>file_path<span class="token punctuation">)</span><span class="token punctuation">:</span>
  user_transcript <span class="token operator">=</span> get_transcript<span class="token punctuation">(</span>file_path<span class="token punctuation">)</span>
  gpt_response <span class="token operator">=</span> get_gpt_response<span class="token punctuation">(</span>user_transcript<span class="token punctuation">,</span> history<span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">10</span><span class="token punctuation">:</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
  gpt_response <span class="token operator">=</span> json<span class="token punctuation">.</span>loads<span class="token punctuation">(</span>gpt_response<span class="token punctuation">)</span>
  gpt_response <span class="token operator">=</span> gpt_response<span class="token punctuation">[</span><span class="token string">'response'</span><span class="token punctuation">]</span>
  history<span class="token punctuation">.</span>extend<span class="token punctuation">(</span><span class="token punctuation">[</span>
      <span class="token punctuation">{</span><span class="token string">"role"</span><span class="token punctuation">:</span> <span class="token string">"user"</span><span class="token punctuation">,</span> <span class="token string">"content"</span><span class="token punctuation">:</span> user_transcript<span class="token punctuation">}</span><span class="token punctuation">,</span> 
      <span class="token punctuation">{</span><span class="token string">"role"</span><span class="token punctuation">:</span> <span class="token string">"assistant"</span><span class="token punctuation">,</span> <span class="token string">"content"</span><span class="token punctuation">:</span> gpt_response<span class="token punctuation">}</span>
  <span class="token punctuation">]</span><span class="token punctuation">)</span></code></pre></div>
<p><img src="https://i.imgur.com/XVEbSg8.png" alt="talking-to-chat-gpt-with-audio"></p>
<p>response도 추가해봤는데 매우 잘된다</p>
<p><img src="https://i.imgur.com/RLm9jFx.png" alt="responsding-to-chat-gpt"></p>
<p>이제 녹음을 구현해서, 사용자의 목소리를 넘겨줘보려고 한다.</p>
<ol>
<li>버튼을 사용해서 사용자가 녹음 시작과 녹음 종료를 알리고</li>
<li>파이썬 패키지를 사용해서 녹음한 내용을 저장하고</li>
<li>저장된 파일의 경로를 <code class="language-text">talk_to_gpt()</code>에 넘겨주면 된다.</li>
</ol>
<p>위 과정은 <a href="https://chat.openai.com/share/0c7d0690-7a27-4d2d-b3d8-d5ada51b20ae" target="_blank" rel="nofollow noopener noreferrer">ChatGPT의 도움</a>을 받아 작성했다.</p>
<p>한가지 아쉬운 부분은 streaming하지 않고 파일을 생성해서 넘겨줘야 한다는 점이다. STT는 온라인, 오프라인 2가지 방식이 있는데. 온라인은 WebSocket등으로 실시간 통신을 하면서 바로바로 음성인식을 시도하는 것이고, 오프라인은 Whisper처럼 파일을 넘겨주는 방식이다. 지금 만드는 기능은 사용자의 발화가 끝날 때 STT결과를 사용해도 충분하니까 괜찮은데, 만약 동시통역처럼 실시간으로 사용자가 말하는 것을 보여줘야 한다면 구현이 조금 더 복잡해질 것 같다.</p>
<p>테스트 해보니 잘 들어간다. 그런데 영어 회화 과외 수업(?) 을 진행하니 ChatGPT의 응답도 읽어주면 어떨까 싶어 <a href="https://platform.openai.com/docs/guides/text-to-speech/text-to-speech" target="_blank" rel="nofollow noopener noreferrer">OpenAI TTS</a>를 추가했다.</p>
<div class="gatsby-highlight" data-language="python"><pre class="language-python"><code class="language-python"><span class="token keyword">import</span> os
<span class="token keyword">from</span> playsound <span class="token keyword">import</span> playsound

<span class="token keyword">def</span> <span class="token function">play_gpt_response_with_tts</span><span class="token punctuation">(</span>gpt_response<span class="token punctuation">)</span><span class="token punctuation">:</span>
  speech_file_path <span class="token operator">=</span> <span class="token string">"./speech.mp3"</span>
  response <span class="token operator">=</span> client<span class="token punctuation">.</span>audio<span class="token punctuation">.</span>speech<span class="token punctuation">.</span>create<span class="token punctuation">(</span>
      model<span class="token operator">=</span><span class="token string">"tts-1"</span><span class="token punctuation">,</span>
      voice<span class="token operator">=</span><span class="token string">"alloy"</span><span class="token punctuation">,</span>
      <span class="token builtin">input</span><span class="token operator">=</span>gpt_response
  <span class="token punctuation">)</span>

  response<span class="token punctuation">.</span>stream_to_file<span class="token punctuation">(</span>speech_file_path<span class="token punctuation">)</span>
  playsound<span class="token punctuation">(</span>speech_file_path<span class="token punctuation">)</span>
  os<span class="token punctuation">.</span>remove<span class="token punctuation">(</span>speech_file_path<span class="token punctuation">)</span></code></pre></div>
<p>공식문서를 보면, 텍스트를 넘겨주면 지정해준 파일 경로로 음성을 저장하는 방식이다. TTS를 위해 생성된 파일이니 음성 파일 재생이 끝나면 해당 파일을 삭제하는 방식으로 구현했다. gpt에서 응답을 받으면 <code class="language-text">play_gpt_response_with_tts()</code>를 호출할 수 있도록 <code class="language-text">talk_to_gpt()</code>를 수정한다</p>
<div class="gatsby-highlight" data-language="python"><pre class="language-python"><code class="language-python"><span class="token keyword">def</span> <span class="token function">talk_to_gpt</span><span class="token punctuation">(</span>file_path<span class="token punctuation">)</span><span class="token punctuation">:</span>
  user_transcript <span class="token operator">=</span> get_transcript<span class="token punctuation">(</span>file_path<span class="token punctuation">)</span>
  gpt_response <span class="token operator">=</span> get_gpt_response<span class="token punctuation">(</span>user_transcript<span class="token punctuation">,</span> history<span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">10</span><span class="token punctuation">:</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
  gpt_response <span class="token operator">=</span> json<span class="token punctuation">.</span>loads<span class="token punctuation">(</span>gpt_response<span class="token punctuation">)</span>
  gpt_response <span class="token operator">=</span> gpt_response<span class="token punctuation">[</span><span class="token string">'response'</span><span class="token punctuation">]</span>
  history<span class="token punctuation">.</span>extend<span class="token punctuation">(</span><span class="token punctuation">[</span>
      <span class="token punctuation">{</span><span class="token string">"role"</span><span class="token punctuation">:</span> <span class="token string">"user"</span><span class="token punctuation">,</span> <span class="token string">"content"</span><span class="token punctuation">:</span> user_transcript<span class="token punctuation">}</span><span class="token punctuation">,</span> 
      <span class="token punctuation">{</span><span class="token string">"role"</span><span class="token punctuation">:</span> <span class="token string">"assistant"</span><span class="token punctuation">,</span> <span class="token string">"content"</span><span class="token punctuation">:</span> gpt_response<span class="token punctuation">}</span>
  <span class="token punctuation">]</span><span class="token punctuation">)</span>
  play_gpt_response_with_tts<span class="token punctuation">(</span>gpt_response<span class="token operator">=</span>gpt_response<span class="token punctuation">)</span></code></pre></div>
<p>코드 작성이 마무리 되었으니 간단하게 테스트를 해봤다.</p>
<p>잘 작동한다.</p>
<div class="gatsby-resp-iframe-wrapper" style="padding-bottom: 56.25%; position: relative; height: 0; overflow: hidden; margin-bottom: 1.0725rem" > <iframe src="https://www.youtube.com/embed/SiT-cB2UL5o?si=BSiVIJKTYlouVcmU" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen="" style=" position: absolute; top: 0; left: 0; width: 100%; height: 100%; "></iframe> </div>
<p>완성된 코드는 <a href="https://github.com/jasonkang14/ai-english-tutor" target="_blank" rel="nofollow noopener noreferrer">GitHub repository</a>에서 확인할 수 있다.</p></div></div></div><div class="Post-module--footer--f8705"><div class="Meta-module--meta--dae0a"><p class="Meta-module--date--4d30d">Published<!-- --> <!-- -->Dec 18, 2023</p></div><div class="Tags-module--tags--18589"><ul class="Tags-module--list--82ae6"><li class="Tags-module--item--52015"><a class="Button-module--button--b1113" href="/tag/llm/">LLM</a></li></ul></div><div class="Author-module--author--1c58d"><p class="Author-module--bio--08950">AI Enthusiast and a Software Engineer<a class="Author-module--twitter--90647" href="https://www.twitter.com/#" rel="noopener noreferrer" target="_blank"><strong>Jason Kang</strong> on Twitter</a></p></div></div><div class="Post-module--comments--d3b99"></div></div></div></div><div id="gatsby-announcer" style="position:absolute;top:0;width:1px;height:1px;padding:0;overflow:hidden;clip:rect(0, 0, 0, 0);white-space:nowrap;border:0" aria-live="assertive" aria-atomic="true"></div></div><script id="gatsby-script-loader">/*<![CDATA[*/window.pagePath="/llm/ai-english-tutor-with-chatgpt-whisper-openai";window.___webpackCompilationHash="662cf0996af6a8b90365";/*]]>*/</script><script id="gatsby-chunk-mapping">/*<![CDATA[*/window.___chunkMapping={"app":["/app-ab191c2654a8bf9f677c.js"],"component---cache-caches-gatsby-plugin-offline-app-shell-js":["/component---cache-caches-gatsby-plugin-offline-app-shell-js-02abafd21f3ca3501462.js"],"component---src-templates-categories-template-categories-template-tsx":["/component---src-templates-categories-template-categories-template-tsx-b449ea18ac689b1b4d05.js"],"component---src-templates-category-template-category-template-tsx":["/component---src-templates-category-template-category-template-tsx-f25335f9ad4d1e083e1e.js"],"component---src-templates-index-template-index-template-tsx":["/component---src-templates-index-template-index-template-tsx-574bb2c842b72a4f56d6.js"],"component---src-templates-not-found-template-not-found-template-tsx":["/component---src-templates-not-found-template-not-found-template-tsx-87d8cb04f32ef1c28bb0.js"],"component---src-templates-page-template-page-template-tsx":["/component---src-templates-page-template-page-template-tsx-beeff9f32d60af6e299a.js"],"component---src-templates-post-template-post-template-tsx":["/component---src-templates-post-template-post-template-tsx-68607055b92e4eb87137.js"],"component---src-templates-tag-template-tag-template-tsx":["/component---src-templates-tag-template-tag-template-tsx-dbf1278bb80575247891.js"],"component---src-templates-tags-template-tags-template-tsx":["/component---src-templates-tags-template-tags-template-tsx-e89bc401e74db52ece1a.js"]};/*]]>*/</script><script src="/app-ab191c2654a8bf9f677c.js" async=""></script><script src="/framework-8a6e3897e8f1c55b7396.js" async=""></script><script src="/webpack-runtime-d65644703f60766379b7.js" async=""></script></body></html>